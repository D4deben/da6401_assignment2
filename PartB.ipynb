{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11431344,"sourceType":"datasetVersion","datasetId":7159659},{"sourceId":11435776,"sourceType":"datasetVersion","datasetId":7162968},{"sourceId":341110,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":285317,"modelId":306151},{"sourceId":344333,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":287894,"modelId":308679}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Installing WandB\n!pip install wandb -qqq","metadata":{"id":"N2pH1fX9EVhL","outputId":"af3350f5-db05-4e9d-a3c4-22e7d8b8834a","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T03:11:54.831585Z","iopub.execute_input":"2025-04-18T03:11:54.831863Z","iopub.status.idle":"2025-04-18T03:11:59.131585Z","shell.execute_reply.started":"2025-04-18T03:11:54.831844Z","shell.execute_reply":"2025-04-18T03:11:59.130815Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Device: \", device)\n\nfrom tqdm import tqdm","metadata":{"id":"-_FwRdhCEfzs","outputId":"62d86701-d418-4c0f-e956-ec36d5059853","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T03:14:04.879530Z","iopub.execute_input":"2025-04-18T03:14:04.879755Z","iopub.status.idle":"2025-04-18T03:14:17.313036Z","shell.execute_reply.started":"2025-04-18T03:14:04.879736Z","shell.execute_reply":"2025-04-18T03:14:17.312272Z"}},"outputs":[{"name":"stdout","text":"Device:  cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import wandb, os\nos.environ['WANDB_API_KEY'] = \"5203e53880ceb7b6d2c0a93809e14ae43261f2ed\" #your key here\nwandb.login()","metadata":{"id":"ahMJIFQ9Egkh","outputId":"65c0d423-4208-4836-ccde-eb39677b35f4","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:22:28.440271Z","iopub.execute_input":"2025-04-18T15:22:28.440475Z","iopub.status.idle":"2025-04-18T15:22:37.293341Z","shell.execute_reply.started":"2025-04-18T15:22:28.440436Z","shell.execute_reply":"2025-04-18T15:22:37.292609Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m016\u001b[0m (\u001b[33mcs24m016-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"!pip install lightning","metadata":{"id":"GbUW9THFFLSt","outputId":"4f2508f7-060f-4b4e-902c-f4af3b322fdc","trusted":true,"execution":{"iopub.status.busy":"2025-04-16T07:23:31.416452Z","iopub.execute_input":"2025-04-16T07:23:31.417185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question 1","metadata":{"id":"1Sa5OfBjM_bV"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass ConvNet(nn.Module):\n    def __init__(\n        self,\n        input_shape=(3, 224, 224),\n        conv_filters=[32, 64, 128, 256, 512],\n        filter_sizes=[3, 3, 3, 3, 3],\n        activation_fn=nn.ReLU,\n        dense_units=256,\n        dense_activation_fn=nn.ReLU,\n        dropout_rate=0.3,\n        batch_norm=True,\n        num_classes=10\n    ):\n        super(ConvNet, self).__init__()\n\n        self.conv_blocks = nn.Sequential()\n        in_channels = input_shape[0]\n        h, w = input_shape[1], input_shape[2]\n\n        # Add 5 Conv-BN-Activation-Pool blocks\n        for i in range(5):\n            out_channels = conv_filters[i]\n            kernel_size = filter_sizes[i]\n            padding = kernel_size // 2  # keep same spatial size before pooling\n\n            self.conv_blocks.add_module(f\"conv{i+1}\", nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding))\n            if batch_norm:\n                self.conv_blocks.add_module(f\"bn{i+1}\", nn.BatchNorm2d(out_channels))\n            self.conv_blocks.add_module(f\"act{i+1}\", activation_fn())\n            self.conv_blocks.add_module(f\"pool{i+1}\", nn.MaxPool2d(2))\n            if dropout_rate > 0:\n                self.conv_blocks.add_module(f\"dropout{i+1}\", nn.Dropout2d(dropout_rate))\n\n            in_channels = out_channels\n            h, w = h // 2, w // 2  # due to MaxPool2d(2)\n\n        # Compute the flattened size after conv blocks\n        self.flattened_size = in_channels * h * w\n\n        self.fc1 = nn.Linear(self.flattened_size, dense_units)\n        self.fc1_act = dense_activation_fn()\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.output_layer = nn.Linear(dense_units, num_classes)\n\n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(self.fc1_act(self.fc1(x)))\n        return self.output_layer(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question 2","metadata":{}},{"cell_type":"code","source":"!pip install wandb\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\n\ndef get_dataloaders(data_dir, batch_size=64, val_split=0.2, augment=True):\n    # Transforms\n    train_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor()\n    ]) if augment else transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    test_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    full_dataset = ImageFolder(root=data_dir, transform=train_transforms)\n\n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(ImageFolder(root=data_dir, transform=test_transforms), val_idx)\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    return train_loader, val_loader, len(full_dataset.classes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nimport wandb\n\ndef train(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n    model.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, correct = 0, 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            correct += (outputs.argmax(dim=1) == labels).sum().item()\n\n        train_accuracy = correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_correct, val_loss = 0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n\n        val_accuracy = val_correct / len(val_loader.dataset)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": total_loss / len(train_loader),\n            \"train_accuracy\": train_accuracy,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_accuracy\n        })\n\n        print(f\"Epoch {epoch+1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\nfrom torch import optim\nimport torch.nn as nn\nimport wandb\n\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n\n    config = wandb.config\n\n    activation_map = {\n        \"ReLU\": nn.ReLU,\n        \"GELU\": nn.GELU,\n        \"SiLU\": nn.SiLU,\n        \"Mish\": nn.Mish\n    }\n\n    model = ConvNet(\n        input_shape=(3, 224, 224),\n        conv_filters=config.conv_filters,\n        filter_sizes=config.filter_sizes,\n        activation_fn=activation_map[config.activation_fn],\n        dense_units=config.dense_units,\n        dense_activation_fn=activation_map[config.activation_fn],\n        dropout_rate=config.dropout,\n        batch_norm=config.batch_norm,\n        num_classes=10\n    )\n\n    train_loader, val_loader, _ = get_dataloaders(\n        data_dir=\"/kaggle/input/nature-12k/inaturalist_12K/train\",\n        batch_size=config.batch_size,\n        augment=config.augment\n    )\n\n    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n\n    train(model, train_loader, val_loader, optimizer, criterion, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), epochs=config.epochs)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[32, 32, 64, 64, 128], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3]]\n        },\n        \"activation_fn\": {\n            \"values\": [\"ReLU\", \"GELU\", \"SiLU\", \"Mish\"]\n        },\n        \"dropout\": {\n            \"values\": [0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128, 256]\n        },\n        \"batch_norm\": {\n            \"values\": [True, False]\n        },\n        \"augment\": {\n            \"values\": [True, False]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 10\n        }\n    }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=5)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=50)\n","metadata":{"trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"gpu mem clear","metadata":{}},{"cell_type":"code","source":"!pip install GPUtil\n\nfrom GPUtil import showUtilization as gpu_usage\ngpu_usage()                             \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install GPUtil\n\nimport torch\nfrom GPUtil import showUtilization as gpu_usage\nfrom numba import cuda\n\ndef free_gpu_cache():\n    print(\"Initial GPU Usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU Usage after emptying the cache\")\n    gpu_usage()\n\nfree_gpu_cache()                           \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# question 3 ","metadata":{}},{"cell_type":"code","source":"\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[32, 32, 64, 64, 128],[512,256,128,64,32],[256,128,64,64,32], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3],[5,5,5,5,5],[7,7,7,7,7],[7,7,5,5,3],[7,5,3,3,3]]\n        },\n        \"activation_fn\": {\n            \"values\": [\"ReLU\", \"GELU\", \"SiLU\", \"Mish\"]\n        },\n        \"dropout\": {\n            \"values\": [0.0,0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128, 256]\n        },\n        \"batch_norm\": {\n            \"values\": [True]\n        },\n        \"augment\": {\n            \"values\": [True, False]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128,256]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 10\n        }\n    }\n}\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    # Enhanced data augmentation\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    \n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n    \n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n    \n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n                             num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, \n                           num_workers=4, pin_memory=True)\n    \n    return train_loader, val_loader, full_dataset.classes\n\nclass OptimizedCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n        \n        # Larger filters in early layers, smaller in later layers\n        self.conv_blocks = nn.Sequential(\n            # Block 1: 64 filters, 7x7 kernel\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 2: 128 filters, 5x5 kernel\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 3: 256 filters, 3x3 kernel\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 4: 512 filters, 3x3 kernel\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 5: 512 filters, 3x3 kernel\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, num_classes))\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, 0, 0.01)\n                init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=20):\n    model.to(device)\n    best_val_acc = 0.0\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_correct += predicted.eq(labels).sum().item()\n        \n        train_acc = 100 * train_correct / len(train_loader.dataset)\n        \n        # Validation\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                val_correct += outputs.argmax(1).eq(labels).sum().item()\n        \n        val_acc = 100 * val_correct / len(val_loader.dataset)\n        \n        # Step the scheduler\n        scheduler.step(val_loss)\n        \n        # Log metrics\n        wandb.log({            \n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n        \n        print(f\"Epoch {epoch+1}/{epochs} - \"\n              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n              f\"Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n    \n    return best_val_acc\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n    \n    # Device configuration\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Get data loaders\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/nature-12k/inaturalist_12K/train\",\n        batch_size=256,\n        augment=True\n    )\n    \n    # Initialize model\n    model = OptimizedCNN(num_classes=len(classes))\n    \n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n    \n    # Optimizer with momentum and weight decay\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    \n    # Train the model\n    best_val_acc = train(\n        model, train_loader, val_loader, \n        optimizer, criterion, scheduler,\n        device=device, epochs=20\n    )\n    \n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Question 4","metadata":{}},{"cell_type":"markdown","source":"# Best Model ","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\n\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[256,128,64,64,32], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3],[7,7,7,7,7]]\n        },\n        \"activation_fn\": {\n            \"values\": [ \"GELU\"]\n        },\n        \"dropout\": {\n            \"values\": [0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128]\n        },\n        \"batch_norm\": {\n            \"values\": [True]\n        },\n        \"augment\": {\n            \"values\": [False]\n        },\n        \"batch_size\": {\n            \"values\": [64,256]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 30\n        }\n    }\n}\n\n\n\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    # Enhanced data augmentation\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    \n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n    \n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n    \n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n                             num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, \n                           num_workers=4, pin_memory=True)\n    \n    return train_loader, val_loader, full_dataset.classes\n\nclass OptimizedCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n        \n        # Larger filters in early layers, smaller in later layers\n        self.conv_blocks = nn.Sequential(\n            # Block 1: 64 filters, 7x7 kernel\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 2: 128 filters, 5x5 kernel\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 3: 256 filters, 3x3 kernel\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 4: 512 filters, 3x3 kernel\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 5: 512 filters, 3x3 kernel\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, num_classes))\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, 0, 0.01)\n                init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=20):\n    model.to(device)\n    best_val_acc = 0.0\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_correct += predicted.eq(labels).sum().item()\n        \n        train_acc = 100 * train_correct / len(train_loader.dataset)\n        \n        # Validation\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                val_correct += outputs.argmax(1).eq(labels).sum().item()\n        \n        val_acc = 100 * val_correct / len(val_loader.dataset)\n        \n        # Step the scheduler\n        scheduler.step(val_loss)\n        \n        # Log metrics\n        wandb.log({            \n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n        \n        print(f\"Epoch {epoch+1}/{epochs} - \"\n              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n              f\"Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n    \n    return best_val_acc\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n    \n    # Device configuration\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Get data loaders\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=256,\n        augment=True\n    )\n    \n    # Initialize model\n    model = OptimizedCNN(num_classes=len(classes))\n    \n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n    \n    # Optimizer with momentum and weight decay\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    \n    # Train the model\n    best_val_acc = train(\n        model, train_loader, val_loader, \n        optimizer, criterion, scheduler,\n        device=device, epochs=30\n    )\n    \n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:49:07.121721Z","iopub.execute_input":"2025-04-16T22:49:07.122054Z","iopub.status.idle":"2025-04-16T22:49:07.683825Z","shell.execute_reply.started":"2025-04-16T22:49:07.122034Z","shell.execute_reply":"2025-04-16T22:49:07.683285Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T22:49:07.684501Z","iopub.execute_input":"2025-04-16T22:49:07.684821Z","iopub.status.idle":"2025-04-17T02:12:54.616587Z","shell.execute_reply.started":"2025-04-16T22:49:07.684803Z","shell.execute_reply":"2025-04-17T02:12:54.612777Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ckiu7skp\nSweep URL: https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lknf7ukr with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [256, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [7, 7, 7, 7, 7]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_224914-lknf7ukr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lknf7ukr' target=\"_blank\">sandy-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lknf7ukr' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lknf7ukr</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.2102, Train Acc: 18.24%, Val Loss: 2.3575, Val Acc: 17.00%\nEpoch 2/30 - Train Loss: 2.1465, Train Acc: 21.89%, Val Loss: 2.2811, Val Acc: 22.10%\nEpoch 3/30 - Train Loss: 2.1058, Train Acc: 23.70%, Val Loss: 2.0659, Val Acc: 26.55%\nEpoch 4/30 - Train Loss: 2.0861, Train Acc: 24.87%, Val Loss: 2.0728, Val Acc: 25.90%\nEpoch 5/30 - Train Loss: 2.0563, Train Acc: 25.00%, Val Loss: 2.1041, Val Acc: 23.00%\nEpoch 6/30 - Train Loss: 2.0689, Train Acc: 25.57%, Val Loss: 2.0626, Val Acc: 24.60%\nEpoch 7/30 - Train Loss: 2.0330, Train Acc: 26.59%, Val Loss: 2.1449, Val Acc: 23.90%\nEpoch 8/30 - Train Loss: 2.0199, Train Acc: 26.84%, Val Loss: 2.0000, Val Acc: 28.80%\nEpoch 9/30 - Train Loss: 2.0084, Train Acc: 26.98%, Val Loss: 1.9952, Val Acc: 29.20%\nEpoch 10/30 - Train Loss: 2.0070, Train Acc: 27.67%, Val Loss: 2.1523, Val Acc: 25.50%\nEpoch 11/30 - Train Loss: 2.0068, Train Acc: 28.18%, Val Loss: 1.9711, Val Acc: 30.60%\nEpoch 12/30 - Train Loss: 1.9800, Train Acc: 29.29%, Val Loss: 1.9619, Val Acc: 29.55%\nEpoch 13/30 - Train Loss: 1.9619, Train Acc: 29.92%, Val Loss: 2.0813, Val Acc: 27.65%\nEpoch 14/30 - Train Loss: 1.9452, Train Acc: 30.73%, Val Loss: 1.9181, Val Acc: 31.25%\nEpoch 15/30 - Train Loss: 1.9679, Train Acc: 29.54%, Val Loss: 1.9531, Val Acc: 32.20%\nEpoch 16/30 - Train Loss: 1.9201, Train Acc: 31.68%, Val Loss: 2.0086, Val Acc: 31.20%\nEpoch 17/30 - Train Loss: 1.9101, Train Acc: 31.99%, Val Loss: 2.2198, Val Acc: 25.90%\nEpoch 18/30 - Train Loss: 1.8893, Train Acc: 32.04%, Val Loss: 1.9498, Val Acc: 33.10%\nEpoch 19/30 - Train Loss: 1.8498, Train Acc: 33.84%, Val Loss: 1.8112, Val Acc: 36.10%\nEpoch 20/30 - Train Loss: 1.7697, Train Acc: 37.34%, Val Loss: 1.7531, Val Acc: 39.35%\nEpoch 21/30 - Train Loss: 1.7568, Train Acc: 37.72%, Val Loss: 1.7536, Val Acc: 40.25%\nEpoch 22/30 - Train Loss: 1.7462, Train Acc: 37.53%, Val Loss: 1.7099, Val Acc: 40.35%\nEpoch 23/30 - Train Loss: 1.7323, Train Acc: 38.47%, Val Loss: 1.7214, Val Acc: 39.60%\nEpoch 24/30 - Train Loss: 1.7348, Train Acc: 38.60%, Val Loss: 1.7000, Val Acc: 40.75%\nEpoch 25/30 - Train Loss: 1.7199, Train Acc: 38.58%, Val Loss: 1.7016, Val Acc: 40.70%\nEpoch 26/30 - Train Loss: 1.7225, Train Acc: 38.89%, Val Loss: 1.7158, Val Acc: 40.70%\nEpoch 27/30 - Train Loss: 1.7249, Train Acc: 38.90%, Val Loss: 1.6863, Val Acc: 41.10%\nEpoch 28/30 - Train Loss: 1.7075, Train Acc: 39.84%, Val Loss: 1.6967, Val Acc: 41.10%\nEpoch 29/30 - Train Loss: 1.6949, Train Acc: 39.55%, Val Loss: 1.6858, Val Acc: 40.90%\nEpoch 30/30 - Train Loss: 1.6872, Train Acc: 39.90%, Val Loss: 1.6690, Val Acc: 41.75%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>█████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇████████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▅▅▄▅▄▄▄▃▂▂▂▂▂▁▁▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▄▃▃▃▄▄▃▅▅▄▅▅▅▄▆▆▇██▇███████</td></tr><tr><td>val_loss</td><td>█▇▅▅▅▅▆▄▄▆▄▄▅▄▄▄▇▄▂▂▂▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>41.75</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>39.90499</td></tr><tr><td>train_loss</td><td>1.68725</td></tr><tr><td>val_accuracy</td><td>41.75</td></tr><tr><td>val_loss</td><td>1.66899</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">sandy-sweep-1</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lknf7ukr' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lknf7ukr</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_224914-lknf7ukr/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5lf2veqv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [256, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_232245-5lf2veqv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/5lf2veqv' target=\"_blank\">light-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/5lf2veqv' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/5lf2veqv</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.2052, Train Acc: 18.26%, Val Loss: 2.2421, Val Acc: 20.55%\nEpoch 2/30 - Train Loss: 2.1291, Train Acc: 22.17%, Val Loss: 2.1544, Val Acc: 22.30%\nEpoch 3/30 - Train Loss: 2.1044, Train Acc: 23.67%, Val Loss: 2.2156, Val Acc: 20.50%\nEpoch 4/30 - Train Loss: 2.0962, Train Acc: 23.85%, Val Loss: 2.0497, Val Acc: 27.15%\nEpoch 5/30 - Train Loss: 2.0717, Train Acc: 25.15%, Val Loss: 2.0553, Val Acc: 25.00%\nEpoch 6/30 - Train Loss: 2.0498, Train Acc: 25.50%, Val Loss: 2.1130, Val Acc: 26.05%\nEpoch 7/30 - Train Loss: 2.0291, Train Acc: 26.79%, Val Loss: 2.0437, Val Acc: 26.05%\nEpoch 8/30 - Train Loss: 2.0239, Train Acc: 27.22%, Val Loss: 2.0706, Val Acc: 26.75%\nEpoch 9/30 - Train Loss: 2.0424, Train Acc: 26.32%, Val Loss: 2.0312, Val Acc: 26.40%\nEpoch 10/30 - Train Loss: 1.9883, Train Acc: 27.90%, Val Loss: 2.0185, Val Acc: 29.45%\nEpoch 11/30 - Train Loss: 1.9875, Train Acc: 28.47%, Val Loss: 1.9602, Val Acc: 29.70%\nEpoch 12/30 - Train Loss: 1.9915, Train Acc: 28.00%, Val Loss: 1.9426, Val Acc: 31.20%\nEpoch 13/30 - Train Loss: 1.9613, Train Acc: 29.82%, Val Loss: 2.0409, Val Acc: 28.80%\nEpoch 14/30 - Train Loss: 1.9528, Train Acc: 29.53%, Val Loss: 1.9189, Val Acc: 32.15%\nEpoch 15/30 - Train Loss: 1.9149, Train Acc: 31.63%, Val Loss: 1.8759, Val Acc: 32.95%\nEpoch 16/30 - Train Loss: 1.9217, Train Acc: 30.95%, Val Loss: 2.2706, Val Acc: 25.30%\nEpoch 17/30 - Train Loss: 1.9227, Train Acc: 31.24%, Val Loss: 1.9359, Val Acc: 32.40%\nEpoch 18/30 - Train Loss: 1.9067, Train Acc: 31.54%, Val Loss: 1.9098, Val Acc: 34.45%\nEpoch 19/30 - Train Loss: 1.9159, Train Acc: 31.62%, Val Loss: 2.0218, Val Acc: 30.45%\nEpoch 20/30 - Train Loss: 1.8277, Train Acc: 35.13%, Val Loss: 1.7574, Val Acc: 38.90%\nEpoch 21/30 - Train Loss: 1.7701, Train Acc: 37.08%, Val Loss: 1.7314, Val Acc: 40.05%\nEpoch 22/30 - Train Loss: 1.7524, Train Acc: 37.57%, Val Loss: 1.7220, Val Acc: 38.95%\nEpoch 23/30 - Train Loss: 1.7347, Train Acc: 38.38%, Val Loss: 1.7195, Val Acc: 39.60%\nEpoch 24/30 - Train Loss: 1.7349, Train Acc: 38.34%, Val Loss: 1.7082, Val Acc: 39.90%\nEpoch 25/30 - Train Loss: 1.7386, Train Acc: 38.48%, Val Loss: 1.7145, Val Acc: 39.35%\nEpoch 26/30 - Train Loss: 1.7176, Train Acc: 39.25%, Val Loss: 1.6865, Val Acc: 40.35%\nEpoch 27/30 - Train Loss: 1.7097, Train Acc: 39.82%, Val Loss: 1.6970, Val Acc: 38.65%\nEpoch 28/30 - Train Loss: 1.6971, Train Acc: 39.90%, Val Loss: 1.6632, Val Acc: 42.10%\nEpoch 29/30 - Train Loss: 1.6969, Train Acc: 39.52%, Val Loss: 1.6869, Val Acc: 41.40%\nEpoch 30/30 - Train Loss: 1.6973, Train Acc: 39.97%, Val Loss: 1.6662, Val Acc: 40.90%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>██████████████████▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▁▃▂▃▃▃▃▄▄▄▄▅▅▃▅▆▄▇▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▇▇▅▆▆▅▆▅▅▄▄▅▄▃█▄▄▅▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>42.1</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>39.9675</td></tr><tr><td>train_loss</td><td>1.69726</td></tr><tr><td>val_accuracy</td><td>40.9</td></tr><tr><td>val_loss</td><td>1.66619</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">light-sweep-2</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/5lf2veqv' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/5lf2veqv</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_232245-5lf2veqv/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 28shrd5m with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250416_235603-28shrd5m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/28shrd5m' target=\"_blank\">pious-sweep-3</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/28shrd5m' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/28shrd5m</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.1960, Train Acc: 18.53%, Val Loss: 2.2380, Val Acc: 19.10%\nEpoch 2/30 - Train Loss: 2.1396, Train Acc: 22.02%, Val Loss: 2.1545, Val Acc: 21.85%\nEpoch 3/30 - Train Loss: 2.0930, Train Acc: 23.58%, Val Loss: 2.0760, Val Acc: 25.10%\nEpoch 4/30 - Train Loss: 2.0963, Train Acc: 24.25%, Val Loss: 2.0846, Val Acc: 24.05%\nEpoch 5/30 - Train Loss: 2.0774, Train Acc: 24.58%, Val Loss: 2.0899, Val Acc: 26.75%\nEpoch 6/30 - Train Loss: 2.0560, Train Acc: 25.93%, Val Loss: 2.0589, Val Acc: 26.95%\nEpoch 7/30 - Train Loss: 2.0551, Train Acc: 25.77%, Val Loss: 2.0797, Val Acc: 26.05%\nEpoch 8/30 - Train Loss: 2.0352, Train Acc: 26.69%, Val Loss: 2.0163, Val Acc: 28.85%\nEpoch 9/30 - Train Loss: 2.0245, Train Acc: 26.98%, Val Loss: 1.9758, Val Acc: 30.15%\nEpoch 10/30 - Train Loss: 2.0054, Train Acc: 28.44%, Val Loss: 2.0389, Val Acc: 27.60%\nEpoch 11/30 - Train Loss: 1.9942, Train Acc: 27.83%, Val Loss: 1.9721, Val Acc: 31.35%\nEpoch 12/30 - Train Loss: 1.9766, Train Acc: 29.02%, Val Loss: 1.9423, Val Acc: 30.95%\nEpoch 13/30 - Train Loss: 1.9519, Train Acc: 29.72%, Val Loss: 1.9000, Val Acc: 32.65%\nEpoch 14/30 - Train Loss: 1.9467, Train Acc: 30.20%, Val Loss: 1.9228, Val Acc: 31.70%\nEpoch 15/30 - Train Loss: 1.9470, Train Acc: 30.07%, Val Loss: 2.1028, Val Acc: 27.90%\nEpoch 16/30 - Train Loss: 1.9439, Train Acc: 30.60%, Val Loss: 1.9431, Val Acc: 33.45%\nEpoch 17/30 - Train Loss: 1.9131, Train Acc: 31.68%, Val Loss: 1.9684, Val Acc: 31.45%\nEpoch 18/30 - Train Loss: 1.8256, Train Acc: 35.22%, Val Loss: 1.7641, Val Acc: 38.60%\nEpoch 19/30 - Train Loss: 1.7640, Train Acc: 36.99%, Val Loss: 1.7376, Val Acc: 38.50%\nEpoch 20/30 - Train Loss: 1.7546, Train Acc: 37.12%, Val Loss: 1.7461, Val Acc: 38.15%\nEpoch 21/30 - Train Loss: 1.7603, Train Acc: 37.25%, Val Loss: 1.7354, Val Acc: 38.25%\nEpoch 22/30 - Train Loss: 1.7335, Train Acc: 38.29%, Val Loss: 1.7148, Val Acc: 39.60%\nEpoch 23/30 - Train Loss: 1.7312, Train Acc: 38.15%, Val Loss: 1.7096, Val Acc: 40.15%\nEpoch 24/30 - Train Loss: 1.7406, Train Acc: 38.38%, Val Loss: 1.7180, Val Acc: 39.45%\nEpoch 25/30 - Train Loss: 1.7339, Train Acc: 38.42%, Val Loss: 1.6959, Val Acc: 40.35%\nEpoch 26/30 - Train Loss: 1.7142, Train Acc: 39.47%, Val Loss: 1.7127, Val Acc: 41.20%\nEpoch 27/30 - Train Loss: 1.7046, Train Acc: 39.53%, Val Loss: 1.7064, Val Acc: 40.65%\nEpoch 28/30 - Train Loss: 1.7007, Train Acc: 38.85%, Val Loss: 1.7011, Val Acc: 39.65%\nEpoch 29/30 - Train Loss: 1.7019, Train Acc: 39.53%, Val Loss: 1.7084, Val Acc: 41.40%\nEpoch 30/30 - Train Loss: 1.6806, Train Acc: 40.29%, Val Loss: 1.6504, Val Acc: 42.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>████████████████▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▂▃▃▃▄▄▄▅▅▅▅▄▅▅▇▇▇▇▇▇▇▇█▇▇██</td></tr><tr><td>val_loss</td><td>█▇▆▆▆▆▆▅▅▆▅▄▄▄▆▄▅▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>42.35</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>40.29254</td></tr><tr><td>train_loss</td><td>1.6806</td></tr><tr><td>val_accuracy</td><td>42.35</td></tr><tr><td>val_loss</td><td>1.6504</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pious-sweep-3</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/28shrd5m' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/28shrd5m</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250416_235603-28shrd5m/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0equy2h8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [7, 7, 7, 7, 7]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_002922-0equy2h8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0equy2h8' target=\"_blank\">unique-sweep-4</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0equy2h8' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0equy2h8</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.1942, Train Acc: 18.10%, Val Loss: 2.2092, Val Acc: 19.35%\nEpoch 2/30 - Train Loss: 2.1247, Train Acc: 22.87%, Val Loss: 2.2178, Val Acc: 23.30%\nEpoch 3/30 - Train Loss: 2.0943, Train Acc: 24.03%, Val Loss: 2.0769, Val Acc: 24.55%\nEpoch 4/30 - Train Loss: 2.0754, Train Acc: 25.30%, Val Loss: 2.0337, Val Acc: 26.75%\nEpoch 5/30 - Train Loss: 2.0541, Train Acc: 25.73%, Val Loss: 2.1464, Val Acc: 23.60%\nEpoch 6/30 - Train Loss: 2.0448, Train Acc: 25.84%, Val Loss: 2.0318, Val Acc: 28.30%\nEpoch 7/30 - Train Loss: 2.0367, Train Acc: 27.17%, Val Loss: 2.0229, Val Acc: 27.05%\nEpoch 8/30 - Train Loss: 2.0085, Train Acc: 27.58%, Val Loss: 2.2619, Val Acc: 25.00%\nEpoch 9/30 - Train Loss: 1.9899, Train Acc: 28.47%, Val Loss: 2.0894, Val Acc: 28.65%\nEpoch 10/30 - Train Loss: 1.9758, Train Acc: 29.09%, Val Loss: 1.9670, Val Acc: 31.25%\nEpoch 11/30 - Train Loss: 1.9655, Train Acc: 29.63%, Val Loss: 1.9811, Val Acc: 31.10%\nEpoch 12/30 - Train Loss: 1.9518, Train Acc: 30.28%, Val Loss: 2.0260, Val Acc: 28.65%\nEpoch 13/30 - Train Loss: 1.9361, Train Acc: 30.94%, Val Loss: 2.0028, Val Acc: 32.05%\nEpoch 14/30 - Train Loss: 1.9313, Train Acc: 31.48%, Val Loss: 1.9013, Val Acc: 31.95%\nEpoch 15/30 - Train Loss: 1.9190, Train Acc: 31.02%, Val Loss: 1.9403, Val Acc: 31.50%\nEpoch 16/30 - Train Loss: 1.9109, Train Acc: 32.57%, Val Loss: 1.8845, Val Acc: 34.45%\nEpoch 17/30 - Train Loss: 1.8816, Train Acc: 33.10%, Val Loss: 1.9495, Val Acc: 33.65%\nEpoch 18/30 - Train Loss: 1.8877, Train Acc: 33.28%, Val Loss: 1.9035, Val Acc: 33.00%\nEpoch 19/30 - Train Loss: 1.8669, Train Acc: 33.78%, Val Loss: 1.9918, Val Acc: 32.10%\nEpoch 20/30 - Train Loss: 1.8825, Train Acc: 32.58%, Val Loss: 1.9851, Val Acc: 31.85%\nEpoch 21/30 - Train Loss: 1.7772, Train Acc: 36.89%, Val Loss: 1.7096, Val Acc: 40.35%\nEpoch 22/30 - Train Loss: 1.7292, Train Acc: 38.39%, Val Loss: 1.7137, Val Acc: 40.90%\nEpoch 23/30 - Train Loss: 1.7258, Train Acc: 39.17%, Val Loss: 1.7039, Val Acc: 41.50%\nEpoch 24/30 - Train Loss: 1.7102, Train Acc: 39.87%, Val Loss: 1.6841, Val Acc: 41.40%\nEpoch 25/30 - Train Loss: 1.6903, Train Acc: 40.03%, Val Loss: 1.6661, Val Acc: 42.20%\nEpoch 26/30 - Train Loss: 1.6900, Train Acc: 40.38%, Val Loss: 1.6636, Val Acc: 43.05%\nEpoch 27/30 - Train Loss: 1.6767, Train Acc: 40.99%, Val Loss: 1.6461, Val Acc: 43.45%\nEpoch 28/30 - Train Loss: 1.6792, Train Acc: 40.76%, Val Loss: 1.6512, Val Acc: 43.15%\nEpoch 29/30 - Train Loss: 1.6738, Train Acc: 40.44%, Val Loss: 1.7046, Val Acc: 41.85%\nEpoch 30/30 - Train Loss: 1.6777, Train Acc: 40.26%, Val Loss: 1.6899, Val Acc: 42.45%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>███████████████████▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▅▇▇▇███████</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▂▄▃▃▄▄▄▄▅▅▅▅▅▅▅▅▇▇▇▇██████</td></tr><tr><td>val_loss</td><td>▇▇▆▅▇▅▅█▆▅▅▅▅▄▄▄▄▄▅▅▂▂▂▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>43.45</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>40.25503</td></tr><tr><td>train_loss</td><td>1.67766</td></tr><tr><td>val_accuracy</td><td>42.45</td></tr><tr><td>val_loss</td><td>1.68988</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">unique-sweep-4</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0equy2h8' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0equy2h8</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_002922-0equy2h8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4h9zdgyq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [256, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_010235-4h9zdgyq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4h9zdgyq' target=\"_blank\">lively-sweep-5</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4h9zdgyq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4h9zdgyq</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.2035, Train Acc: 18.18%, Val Loss: 2.1724, Val Acc: 22.20%\nEpoch 2/30 - Train Loss: 2.1374, Train Acc: 21.53%, Val Loss: 2.0869, Val Acc: 23.40%\nEpoch 3/30 - Train Loss: 2.0977, Train Acc: 23.50%, Val Loss: 2.0843, Val Acc: 24.95%\nEpoch 4/30 - Train Loss: 2.0892, Train Acc: 23.83%, Val Loss: 2.0459, Val Acc: 25.40%\nEpoch 5/30 - Train Loss: 2.0618, Train Acc: 25.77%, Val Loss: 2.0605, Val Acc: 25.45%\nEpoch 6/30 - Train Loss: 2.0402, Train Acc: 26.43%, Val Loss: 2.0509, Val Acc: 26.30%\nEpoch 7/30 - Train Loss: 2.0423, Train Acc: 27.20%, Val Loss: 1.9934, Val Acc: 28.00%\nEpoch 8/30 - Train Loss: 2.0058, Train Acc: 28.22%, Val Loss: 2.1463, Val Acc: 25.60%\nEpoch 9/30 - Train Loss: 2.0067, Train Acc: 27.74%, Val Loss: 1.9837, Val Acc: 30.00%\nEpoch 10/30 - Train Loss: 1.9863, Train Acc: 28.78%, Val Loss: 2.1871, Val Acc: 25.45%\nEpoch 11/30 - Train Loss: 1.9884, Train Acc: 28.67%, Val Loss: 2.0306, Val Acc: 26.65%\nEpoch 12/30 - Train Loss: 1.9931, Train Acc: 27.84%, Val Loss: 2.0172, Val Acc: 28.75%\nEpoch 13/30 - Train Loss: 1.9485, Train Acc: 29.77%, Val Loss: 2.0522, Val Acc: 28.95%\nEpoch 14/30 - Train Loss: 1.8872, Train Acc: 32.30%, Val Loss: 1.8072, Val Acc: 35.90%\nEpoch 15/30 - Train Loss: 1.8308, Train Acc: 34.85%, Val Loss: 1.7896, Val Acc: 37.40%\nEpoch 16/30 - Train Loss: 1.8135, Train Acc: 35.50%, Val Loss: 1.7819, Val Acc: 37.40%\nEpoch 17/30 - Train Loss: 1.8036, Train Acc: 36.32%, Val Loss: 1.7540, Val Acc: 38.70%\nEpoch 18/30 - Train Loss: 1.7901, Train Acc: 35.97%, Val Loss: 1.7678, Val Acc: 38.40%\nEpoch 19/30 - Train Loss: 1.7849, Train Acc: 36.88%, Val Loss: 1.7782, Val Acc: 37.90%\nEpoch 20/30 - Train Loss: 1.7677, Train Acc: 37.17%, Val Loss: 1.7514, Val Acc: 38.65%\nEpoch 21/30 - Train Loss: 1.7668, Train Acc: 36.67%, Val Loss: 1.8236, Val Acc: 36.75%\nEpoch 22/30 - Train Loss: 1.7602, Train Acc: 37.52%, Val Loss: 1.7359, Val Acc: 38.75%\nEpoch 23/30 - Train Loss: 1.7543, Train Acc: 37.12%, Val Loss: 1.7277, Val Acc: 39.80%\nEpoch 24/30 - Train Loss: 1.7521, Train Acc: 37.55%, Val Loss: 1.7476, Val Acc: 39.25%\nEpoch 25/30 - Train Loss: 1.7578, Train Acc: 37.19%, Val Loss: 1.7382, Val Acc: 39.20%\nEpoch 26/30 - Train Loss: 1.7490, Train Acc: 38.02%, Val Loss: 1.7026, Val Acc: 40.65%\nEpoch 27/30 - Train Loss: 1.7436, Train Acc: 38.43%, Val Loss: 1.7310, Val Acc: 40.25%\nEpoch 28/30 - Train Loss: 1.7197, Train Acc: 38.74%, Val Loss: 1.7464, Val Acc: 39.05%\nEpoch 29/30 - Train Loss: 1.7220, Train Acc: 38.65%, Val Loss: 1.6806, Val Acc: 40.95%\nEpoch 30/30 - Train Loss: 1.7250, Train Acc: 39.39%, Val Loss: 1.8738, Val Acc: 36.80%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>████████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▄▄▄▄▄▄▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▇▆▆▆▆▆▅▅▅▅▅▄▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▂▂▃▃▂▄▂▃▃▄▆▇▇▇▇▇▇▆▇█▇▇██▇█▆</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▅▇▅█▆▆▆▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>40.95</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>39.39242</td></tr><tr><td>train_loss</td><td>1.72496</td></tr><tr><td>val_accuracy</td><td>36.8</td></tr><tr><td>val_loss</td><td>1.87376</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lively-sweep-5</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4h9zdgyq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4h9zdgyq</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_010235-4h9zdgyq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zvvvpj24 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [7, 7, 7, 7, 7]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_013557-zvvvpj24</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zvvvpj24' target=\"_blank\">eternal-sweep-6</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zvvvpj24' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zvvvpj24</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.1991, Train Acc: 17.76%, Val Loss: 2.2476, Val Acc: 17.25%\nEpoch 2/30 - Train Loss: 2.1265, Train Acc: 22.19%, Val Loss: 2.2045, Val Acc: 23.10%\nEpoch 3/30 - Train Loss: 2.0889, Train Acc: 23.97%, Val Loss: 2.0915, Val Acc: 26.45%\nEpoch 4/30 - Train Loss: 2.0612, Train Acc: 24.93%, Val Loss: 2.3098, Val Acc: 20.85%\nEpoch 5/30 - Train Loss: 2.0449, Train Acc: 26.57%, Val Loss: 2.0976, Val Acc: 23.95%\nEpoch 6/30 - Train Loss: 2.0451, Train Acc: 26.50%, Val Loss: 2.1063, Val Acc: 25.80%\nEpoch 7/30 - Train Loss: 2.0252, Train Acc: 27.14%, Val Loss: 2.0415, Val Acc: 25.80%\nEpoch 8/30 - Train Loss: 1.9970, Train Acc: 28.38%, Val Loss: 1.9918, Val Acc: 28.50%\nEpoch 9/30 - Train Loss: 1.9847, Train Acc: 28.69%, Val Loss: 1.9931, Val Acc: 29.45%\nEpoch 10/30 - Train Loss: 1.9548, Train Acc: 29.98%, Val Loss: 2.0423, Val Acc: 30.65%\nEpoch 11/30 - Train Loss: 1.9607, Train Acc: 30.00%, Val Loss: 1.9788, Val Acc: 31.40%\nEpoch 12/30 - Train Loss: 1.9523, Train Acc: 29.93%, Val Loss: 1.9415, Val Acc: 30.30%\nEpoch 13/30 - Train Loss: 1.9420, Train Acc: 30.07%, Val Loss: 1.9596, Val Acc: 30.15%\nEpoch 14/30 - Train Loss: 1.9426, Train Acc: 30.28%, Val Loss: 1.9306, Val Acc: 32.35%\nEpoch 15/30 - Train Loss: 1.9132, Train Acc: 31.67%, Val Loss: 2.0207, Val Acc: 30.45%\nEpoch 16/30 - Train Loss: 1.9275, Train Acc: 31.69%, Val Loss: 1.8629, Val Acc: 33.05%\nEpoch 17/30 - Train Loss: 1.8884, Train Acc: 33.05%, Val Loss: 1.9520, Val Acc: 32.25%\nEpoch 18/30 - Train Loss: 1.8759, Train Acc: 33.38%, Val Loss: 1.9035, Val Acc: 33.25%\nEpoch 19/30 - Train Loss: 1.8700, Train Acc: 33.29%, Val Loss: 1.8491, Val Acc: 36.60%\nEpoch 20/30 - Train Loss: 1.8728, Train Acc: 33.24%, Val Loss: 1.8933, Val Acc: 35.45%\nEpoch 21/30 - Train Loss: 1.8565, Train Acc: 34.03%, Val Loss: 1.8646, Val Acc: 35.30%\nEpoch 22/30 - Train Loss: 1.8388, Train Acc: 34.90%, Val Loss: 1.8540, Val Acc: 37.20%\nEpoch 23/30 - Train Loss: 1.8351, Train Acc: 35.07%, Val Loss: 1.8347, Val Acc: 37.15%\nEpoch 24/30 - Train Loss: 1.7982, Train Acc: 36.09%, Val Loss: 1.8953, Val Acc: 35.40%\nEpoch 25/30 - Train Loss: 1.8191, Train Acc: 35.34%, Val Loss: 1.9176, Val Acc: 34.40%\nEpoch 26/30 - Train Loss: 1.8020, Train Acc: 36.48%, Val Loss: 1.9129, Val Acc: 35.30%\nEpoch 27/30 - Train Loss: 1.7835, Train Acc: 36.24%, Val Loss: 2.0068, Val Acc: 33.00%\nEpoch 28/30 - Train Loss: 1.6974, Train Acc: 39.99%, Val Loss: 1.6356, Val Acc: 42.75%\nEpoch 29/30 - Train Loss: 1.6408, Train Acc: 42.04%, Val Loss: 1.6359, Val Acc: 41.50%\nEpoch 30/30 - Train Loss: 1.6414, Train Acc: 41.94%, Val Loss: 1.6207, Val Acc: 43.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>██████████████████████████▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▇██</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▆▆▅▅▅▅▅▅▅▄▅▄▄▄▄▄▃▃▃▃▃▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▂▃▃▃▄▄▅▅▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▅█▇█</td></tr><tr><td>val_loss</td><td>▇▇▆█▆▆▅▅▅▅▅▄▄▄▅▃▄▄▃▄▃▃▃▄▄▄▅▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>43.5</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>41.94274</td></tr><tr><td>train_loss</td><td>1.64145</td></tr><tr><td>val_accuracy</td><td>43.5</td></tr><tr><td>val_loss</td><td>1.62069</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eternal-sweep-6</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zvvvpj24' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zvvvpj24</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_013557-zvvvpj24/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4p66no5p with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation_fn: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_filters: [32, 64, 128, 256, 512]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_units: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_020926-4p66no5p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4p66no5p' target=\"_blank\">absurd-sweep-7</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ckiu7skp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4p66no5p' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4p66no5p</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Loss: 2.2048, Train Acc: 18.15%, Val Loss: 2.3809, Val Acc: 18.35%\nEpoch 2/30 - Train Loss: 2.1295, Train Acc: 22.78%, Val Loss: 2.1052, Val Acc: 23.90%\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#1. Testing the Best Model and Creating Prediction Grid\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torchvision.utils import make_grid\n\ndef test_model(model, test_loader, device, classes):\n    model.eval()\n    test_correct = 0\n    all_preds = []\n    all_images = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            test_correct += preds.eq(labels).sum().item()\n            all_preds.extend(preds.cpu().numpy())\n            all_images.extend(images.cpu())\n            all_labels.extend(labels.cpu().numpy())\n    \n    test_acc = 100 * test_correct / len(test_loader.dataset)\n    print(f'Test Accuracy: {test_acc:.2f}%')\n    \n    return test_acc, all_images, all_labels, all_preds\n\ndef create_prediction_grid(images, labels, preds, classes, n=10):\n    # Create a figure with n rows and 3 columns\n    fig, axes = plt.subplots(n, 3, figsize=(10, 3*n))\n    \n    # Get random indices for samples\n    indices = np.random.choice(len(images), n, replace=False)\n    \n    for i, idx in enumerate(indices):\n        # Original image\n        img = images[idx].permute(1, 2, 0).numpy()\n        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # Unnormalize\n        img = np.clip(img, 0, 1)\n        \n        axes[i, 0].imshow(img)\n        axes[i, 0].axis('off')\n        if i == 0:\n            axes[i, 0].set_title('Original Image')\n        \n        # True label\n        true_label = classes[labels[idx]]\n        axes[i, 1].text(0.5, 0.5, f'True: {true_label}', \n                       ha='center', va='center', fontsize=12)\n        axes[i, 1].axis('off')\n        if i == 0:\n            axes[i, 1].set_title('True Label')\n        \n        # Predicted label (color red if wrong, green if correct)\n        pred_label = classes[preds[idx]]\n        color = 'red' if preds[idx] != labels[idx] else 'green'\n        axes[i, 2].text(0.5, 0.5, f'Pred: {pred_label}', \n                        ha='center', va='center', fontsize=12, color=color)\n        axes[i, 2].axis('off')\n        if i == 0:\n            axes[i, 2].set_title('Prediction')\n    \n    plt.tight_layout()\n    plt.savefig('prediction_grid.png', bbox_inches='tight')\n    plt.show()\n\n# Load test data\ntest_transforms = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_dataset = datasets.ImageFolder(\n    root=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val\",  # Using val as test\n    transform=test_transforms\n)\n\ntest_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n\n# Load best model\nbest_model = OptimizedCNN(num_classes=len(test_dataset.classes))\nbest_model.load_state_dict(torch.load('/kaggle/input/cnn/pytorch/default/1/best_model.pth'))\nbest_model.to(device)\n\n# Test and create grid\ntest_acc, test_images, test_labels, test_preds = test_model(best_model, test_loader, device, test_dataset.classes)\ncreate_prediction_grid(test_images, test_labels, test_preds, test_dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:02:33.776412Z","iopub.execute_input":"2025-04-16T20:02:33.776922Z","iopub.status.idle":"2025-04-16T20:02:47.336113Z","shell.execute_reply.started":"2025-04-16T20:02:33.776898Z","shell.execute_reply":"2025-04-16T20:02:47.334991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"need to change the grid and visualize on wandb","metadata":{}},{"cell_type":"code","source":"# Visualizing First Layer Filters\ndef visualize_first_layer_filters(model, image, save_path='first_layer_filters.png'):\n    # Get first conv layer weights\n    first_conv = model.conv_blocks[0]\n    filters = first_conv.weight.data.cpu().numpy()\n    \n    # Normalize filters to 0-1 for visualization\n    f_min, f_max = filters.min(), filters.max()\n    filters = (filters - f_min) / (f_max - f_min)\n    \n    # Plot filters in 8x8 grid\n    fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n    \n    for i in range(8):\n        for j in range(8):\n            idx = i * 8 + j\n            if idx < filters.shape[0]:  # In case we have less than 64 filters\n                filter_img = filters[idx].transpose(1, 2, 0)\n                axes[i, j].imshow(filter_img)\n                axes[i, j].axis('off')\n            else:\n                axes[i, j].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(save_path, bbox_inches='tight')\n    plt.show()\n\n# Get a random test image\nrandom_idx = np.random.randint(len(test_dataset))\nimage, _ = test_dataset[random_idx]\nimage = image.unsqueeze(0).to(device)\n\n# Visualize filters\nvisualize_first_layer_filters(best_model, image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:42:15.209332Z","iopub.execute_input":"2025-04-16T20:42:15.210016Z","iopub.status.idle":"2025-04-16T20:42:17.246693Z","shell.execute_reply.started":"2025-04-16T20:42:15.209989Z","shell.execute_reply":"2025-04-16T20:42:17.246035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport wandb\n\ndef visualize_first_layer(model, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Load transformation\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load test dataset and get random image\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    random_idx = np.random.randint(0, len(test_dataset))\n    img, label = test_dataset[random_idx]\n    img = img.unsqueeze(0).to(device)  # Add batch dimension\n    \n    # Get the first convolutional layer\n    first_conv = model.conv_blocks[0]\n    num_filters = first_conv.out_channels  # Dynamically get number of filters\n    \n    # Visualize filters\n    filters = first_conv.weight.data.cpu().numpy()\n    \n    # Normalize filters to 0-1 for visualization\n    f_min, f_max = filters.min(), filters.max()\n    filters = (filters - f_min) / (f_max - f_min)\n    \n    # Calculate grid size (square as possible)\n    grid_size = int(np.ceil(np.sqrt(num_filters)))\n    \n    # Plot filters\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        # Show first channel only (assuming RGB input)\n        plt.imshow(filters[i, 0], cmap='gray')\n        plt.axis('off')\n    plt.suptitle(f'First Layer Filters ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    filters_fig = plt.gcf()\n    \n    # Get feature maps\n    model.eval()\n    with torch.no_grad():\n        feature_maps = first_conv(img)\n    \n    # Normalize feature maps\n    fmaps = feature_maps.squeeze(0).cpu().numpy()\n    fmap_min, fmap_max = fmaps.min(), fmaps.max()\n    fmaps = (fmaps - fmap_min) / (fmap_max - fmap_min)\n    \n    # Plot feature maps\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        plt.imshow(fmaps[i], cmap='viridis')\n        plt.axis('off')\n    plt.suptitle(f'Feature Maps ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    fmap_fig = plt.gcf()\n    \n    # Show original image (denormalized)\n    img_denorm = img.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n    img_denorm = img_denorm * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n    img_denorm = np.clip(img_denorm, 0, 1)\n    \n    plt.figure(figsize=(8, 8))\n    plt.imshow(img_denorm)\n    plt.title(f'Original Test Image\\nClass: {test_dataset.classes[label]}')\n    plt.axis('off')\n    orig_fig = plt.gcf()\n    \n    # Additional analysis\n    # 1. Filter magnitude distribution\n    filter_magnitudes = torch.norm(first_conv.weight.data, dim=(1, 2, 3)).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.hist(filter_magnitudes, bins=20)\n    plt.title('Filter Magnitude Distribution')\n    plt.xlabel('Magnitude (L2 norm)')\n    plt.ylabel('Count')\n    magnitude_fig = plt.gcf()\n    \n    # 2. Activation statistics\n    activation_means = feature_maps.mean(dim=(0, 2, 3)).cpu().numpy()\n    activation_max = feature_maps.amax(dim=(0, 2, 3)).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.bar(range(num_filters), activation_means, alpha=0.5, label='Mean')\n    plt.bar(range(num_filters), activation_max, alpha=0.5, label='Max')\n    plt.title('Feature Map Activation Statistics')\n    plt.xlabel('Filter Index')\n    plt.ylabel('Activation Value')\n    plt.legend()\n    activation_fig = plt.gcf()\n    \n    # Log to wandb\n    wandb.init(project=\"DL_A2\", name=\"filter_visualization\")\n    wandb.log({\n        \"original_image\": wandb.Image(orig_fig),\n        \"first_layer_filters\": wandb.Image(filters_fig),\n        \"feature_maps\": wandb.Image(fmap_fig),\n        \"filter_magnitudes\": wandb.Image(magnitude_fig),\n        \"activation_stats\": wandb.Image(activation_fig),\n        \"selected_class\": test_dataset.classes[label]\n    })\n    \n    plt.close('all')\n    return {\n        \"num_filters\": num_filters,\n        \"filter_magnitudes\": filter_magnitudes,\n        \"activation_means\": activation_means,\n        \"activation_max\": activation_max\n    }\n\n# Load your model\nmodel = OptimizedCNN(num_classes=len(test_dataset.classes))  # Adjust as needed\nmodel.load_state_dict(torch.load('/kaggle/input/cnn/pytorch/default/1/best_model.pth'))\nmodel = model.to(device)\n\n# Run visualization\nresults = visualize_first_layer(\n    model, \n    test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:44:42.248877Z","iopub.execute_input":"2025-04-16T20:44:42.249563Z","iopub.status.idle":"2025-04-16T20:44:46.872356Z","shell.execute_reply.started":"2025-04-16T20:44:42.249542Z","shell.execute_reply":"2025-04-16T20:44:46.871377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# best feature map ","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport wandb\n\ndef visualize_first_layer(model, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Load transformation\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load test dataset and get random image\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    random_idx = np.random.randint(0, len(test_dataset))\n    img, label = test_dataset[random_idx]\n    img = img.unsqueeze(0).to(device)  # Add batch dimension\n    \n    # Get the first convolutional layer\n    first_conv = model.conv_blocks[0]\n    num_filters = first_conv.out_channels  # Dynamically get number of filters\n    \n    # Visualize filters\n    filters = first_conv.weight.data.cpu().numpy()\n    \n    # Normalize filters to 0-1 for visualization\n    f_min, f_max = filters.min(), filters.max()\n    filters = (filters - f_min) / (f_max - f_min)\n    \n    # Calculate grid size (square as possible)\n    grid_size = int(np.ceil(np.sqrt(num_filters)))\n    \n    # Plot filters\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        # Show first channel only (assuming RGB input)\n        plt.imshow(filters[i, 0], cmap='gray')\n        plt.axis('off')\n    plt.suptitle(f'First Layer Filters ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    filters_fig = plt.gcf()\n    \n    # Get feature maps\n    model.eval()\n    with torch.no_grad():\n        feature_maps = first_conv(img)\n    \n    # Normalize feature maps\n    fmaps = feature_maps.squeeze(0).cpu().numpy()\n    fmap_min, fmap_max = fmaps.min(), fmaps.max()\n    fmaps = (fmaps - fmap_min) / (fmap_max - fmap_min)\n    \n    # Plot feature maps\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        plt.imshow(fmaps[i], cmap='viridis')\n        plt.axis('off')\n    plt.suptitle(f'Feature Maps ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    fmap_fig = plt.gcf()\n    \n    # Show original image (denormalized)\n    img_denorm = img.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n    img_denorm = img_denorm * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n    img_denorm = np.clip(img_denorm, 0, 1)\n    \n    plt.figure(figsize=(8, 8))\n    plt.imshow(img_denorm)\n    plt.title(f'Original Test Image\\nClass: {test_dataset.classes[label]}')\n    plt.axis('off')\n    orig_fig = plt.gcf()\n    \n    # Additional analysis\n    # 1. Filter magnitude distribution (fixed calculation)\n    filter_magnitudes = torch.norm(first_conv.weight.data.view(num_filters, -1), p=2, dim=1).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.hist(filter_magnitudes, bins=20)\n    plt.title('Filter Magnitude Distribution')\n    plt.xlabel('Magnitude (L2 norm)')\n    plt.ylabel('Count')\n    magnitude_fig = plt.gcf()\n    \n    # 2. Activation statistics\n    activation_means = feature_maps.mean(dim=(0, 2, 3)).cpu().numpy()\n    activation_max = feature_maps.amax(dim=(0, 2, 3)).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.bar(range(num_filters), activation_means, alpha=0.5, label='Mean')\n    plt.bar(range(num_filters), activation_max, alpha=0.5, label='Max')\n    plt.title('Feature Map Activation Statistics')\n    plt.xlabel('Filter Index')\n    plt.ylabel('Activation Value')\n    plt.legend()\n    activation_fig = plt.gcf()\n    \n    # Log to wandb\n    wandb.init(project=\"DL_A2\", name=\"filter_visualization\")\n    wandb.log({\n        \"original_image\": wandb.Image(orig_fig),\n        \"first_layer_filters\": wandb.Image(filters_fig),\n        \"feature_maps\": wandb.Image(fmap_fig),\n        \"filter_magnitudes\": wandb.Image(magnitude_fig),\n        \"activation_stats\": wandb.Image(activation_fig),\n        \"selected_class\": test_dataset.classes[label]\n    })\n    \n    plt.close('all')\n    return {\n        \"num_filters\": num_filters,\n        \"filter_magnitudes\": filter_magnitudes,\n        \"activation_means\": activation_means,\n        \"activation_max\": activation_max\n    }\n\n# Load your model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val', transform=transforms.ToTensor())\nmodel = OptimizedCNN(num_classes=len(test_dataset.classes))\nmodel.load_state_dict(torch.load('/kaggle/input/cnn/pytorch/default/1/best_model.pth', map_location=device))\nmodel = model.to(device)\n\n# Run visualization\nresults = visualize_first_layer(\n    model, \n    test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:50:50.046278Z","iopub.execute_input":"2025-04-16T20:50:50.046457Z","iopub.status.idle":"2025-04-16T20:50:55.258174Z","shell.execute_reply.started":"2025-04-16T20:50:50.046442Z","shell.execute_reply":"2025-04-16T20:50:55.257645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom collections import defaultdict\nimport wandb\nimport random\nfrom PIL import Image\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\n\ndef create_enhanced_grid(images, labels, preds, class_names, n_rows=10, n_cols=3, title=\"Predictions\"):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows*2.5))\n    fig.suptitle(title, fontsize=16, y=1.02)\n    \n    for i in range(n_rows):\n        for j in range(n_cols):\n            idx = i * n_cols + j\n            if idx >= len(images):\n                break\n                \n            ax = axes[i,j]\n            img = images[idx].numpy().transpose((1, 2, 0))\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img = np.clip((img * std + mean), 0, 1)\n            \n            ax.imshow(img)\n            ax.axis('off')\n            \n            true_label = class_names[labels[idx]]\n            pred_label = class_names[preds[idx]]\n            is_correct = preds[idx] == labels[idx]\n            \n            # More informative title with confidence if available\n            title_color = 'green' if is_correct else 'red'\n            title_text = f\"True: {true_label}\\nPred: {pred_label}\"\n            \n            if is_correct:\n                title_text += \"\\n Correct\"\n            else:\n                title_text += \"\\n Wrong\"\n                \n            ax.set_title(title_text, fontsize=9, color=title_color, pad=2)\n    \n    plt.tight_layout()\n    return fig\n\ndef plot_confusion_matrix(y_true, y_pred, class_names):\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(12, 10))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.xticks(rotation=45, ha='right')\n    plt.yticks(rotation=0)\n    return plt.gcf()\n\ndef evaluate_testset(model_path, test_dir, num_grids=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=4)\n    class_names = dataset.classes\n\n    model = OptimizedCNN(num_classes=len(class_names))\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Collect all predictions\n    all_images, all_labels, all_preds = [], [], []\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu()\n            all_images.extend(images.cpu())\n            all_labels.extend(labels)\n            all_preds.extend(preds)\n\n    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    wandb.init(project=\"DL_A2\", name=\"test_evaluation\", job_type=\"eval\")\n\n    wandb.log({\"test_accuracy\": accuracy})\n\n    # Class-wise accuracy with zero-division handling\n    class_correct = defaultdict(int)\n    class_total = defaultdict(int)\n    \n    for label, pred in zip(all_labels, all_preds):\n        class_total[label] += 1\n        if label == pred:\n            class_correct[label] += 1\n    \n    # Calculate accuracy only for classes that have samples\n    class_acc = {}\n    for i in range(len(class_names)):\n        if class_total[i] > 0:\n            class_acc[class_names[i]] = 100 * class_correct[i] / class_total[i]\n        else:\n            class_acc[class_names[i]] = float('nan')  # Mark as NaN if no samples\n    \n    # Create wandb table\n    wandb.log({\"class_accuracy\": wandb.Table(\n        columns=[\"Class\", \"Accuracy\", \"Samples\"],\n        data=[[class_names[i], \n              class_acc[class_names[i]], \n              class_total[i]] \n             for i in range(len(class_names))]\n    )})\n\n    # Confusion matrix (only for classes with samples)\n    present_classes = [i for i in range(len(class_names)) if class_total[i] > 0]\n    present_labels = [l for l in all_labels if l in present_classes]\n    present_preds = [p for i, p in enumerate(all_preds) if all_labels[i] in present_classes]\n    \n    if present_classes:\n        cm = confusion_matrix(present_labels, present_preds, labels=present_classes)\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                   xticklabels=[class_names[i] for i in present_classes],\n                   yticklabels=[class_names[i] for i in present_classes])\n        plt.title('Confusion Matrix (for classes with samples)')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.xticks(rotation=45, ha='right')\n        plt.yticks(rotation=0)\n        wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n        plt.close()\n\n    # Create prediction grids only for classes with samples\n    present_indices = [i for i in range(len(all_labels)) if all_labels[i] in present_classes]\n    if present_indices:\n        for i in range(min(num_grids, 10)):  # Ensure we don't request more grids than possible\n            sample_size = min(30, len(present_indices))  # 10x3 grid\n            indices = random.sample(present_indices, sample_size)\n            sample_imgs = [all_images[j] for j in indices]\n            sample_labels = [all_labels[j] for j in indices]\n            sample_preds = [all_preds[j] for j in indices]\n\n            fig = create_enhanced_grid(\n                sample_imgs, sample_labels, sample_preds, \n                class_names, n_rows=10, n_cols=3,\n                title=f\"Sample Predictions - Grid {i+1}\"\n            )\n            wandb.log({f\"prediction_grid_{i}\": wandb.Image(fig)})\n            plt.close(fig)\n\n    wandb.finish()\n\nif __name__ == \"__main__\":\n    evaluate_testset(\n        model_path='/kaggle/input/cnn/pytorch/default/1/best_model.pth',\n        test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val',\n        num_grids=10\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:18:12.819427Z","iopub.execute_input":"2025-04-16T20:18:12.820137Z","iopub.status.idle":"2025-04-16T20:18:28.422034Z","shell.execute_reply.started":"2025-04-16T20:18:12.820109Z","shell.execute_reply":"2025-04-16T20:18:28.421434Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#   best visualization for test dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom collections import defaultdict\nimport wandb\nimport random\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef create_prediction_grid(images, labels, preds, class_names, n_rows=10, n_cols=3, title=\"Predictions\"):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows*2))\n    fig.suptitle(title, fontsize=16, y=1.02)\n    \n    for i in range(n_rows):\n        for j in range(n_cols):\n            idx = i * n_cols + j\n            if idx >= len(images):\n                break\n                \n            ax = axes[i,j]\n            img = images[idx].numpy().transpose((1, 2, 0))\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img = np.clip((img * std + mean), 0, 1)\n            \n            ax.imshow(img)\n            ax.axis('off')\n            \n            true_label = class_names[labels[idx]]\n            pred_label = class_names[preds[idx]]\n            is_correct = preds[idx] == labels[idx]\n            \n            title_color = 'green' if is_correct else 'red'\n            title_text = f\"True: {true_label}\\nPred: {pred_label}\"\n            ax.set_title(title_text, fontsize=9, color=title_color, pad=2)\n    \n    plt.tight_layout()\n    return fig\n\ndef evaluate_testset(model_path, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Same transforms as validation\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load test dataset\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n    class_names = test_dataset.classes\n\n    # Load model\n    model = OptimizedCNN(num_classes=len(class_names))\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Collect predictions and ground truth\n    all_images = []\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_images.extend(images.cpu())\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n\n    # Calculate overall accuracy\n    accuracy = 100 * np.sum(np.array(all_labels) == np.array(all_preds)) / len(all_labels)\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    # Initialize wandb\n    wandb.init(project=\"DL_A2\", name=\"test_evaluation\", job_type=\"eval\")\n    wandb.log({\"test_accuracy\": accuracy})\n\n    # Calculate class-wise accuracy\n    class_correct = defaultdict(int)\n    class_total = defaultdict(int)\n    \n    for label, pred in zip(all_labels, all_preds):\n        class_total[label] += 1\n        if label == pred:\n            class_correct[label] += 1\n    \n    # Create accuracy table\n    accuracy_table = wandb.Table(columns=[\"Class\", \"Accuracy\", \"Samples\"])\n    for class_idx in range(len(class_names)):\n        if class_total[class_idx] > 0:\n            acc = 100 * class_correct[class_idx] / class_total[class_idx]\n        else:\n            acc = float('nan')\n        accuracy_table.add_data(class_names[class_idx], acc, class_total[class_idx])\n    \n    wandb.log({\"class_accuracy\": accuracy_table})\n\n    # Create confusion matrix (only for classes with samples)\n    present_classes = [c for c in range(len(class_names)) if class_total[c] > 0]\n    if present_classes:\n        cm = confusion_matrix(all_labels, all_preds, labels=present_classes)\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                   xticklabels=[class_names[c] for c in present_classes],\n                   yticklabels=[class_names[c] for c in present_classes])\n        plt.title('Confusion Matrix')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.xticks(rotation=45, ha='right')\n        plt.yticks(rotation=0)\n        wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n        plt.close()\n\n    # Create 10x3 prediction grid\n    num_samples = 30  # 10 rows x 3 columns\n    if len(all_images) >= num_samples:\n        indices = random.sample(range(len(all_images)), num_samples)\n        sample_images = [all_images[i] for i in indices]\n        sample_labels = [all_labels[i] for i in indices]\n        sample_preds = [all_preds[i] for i in indices]\n        \n        grid_fig = create_prediction_grid(\n            sample_images, sample_labels, sample_preds, \n            class_names, title=\"Test Set Predictions (Random Sample)\"\n        )\n        wandb.log({\"prediction_grid\": wandb.Image(grid_fig)})\n        plt.close(grid_fig)\n    else:\n        print(f\"Not enough samples ({len(all_images)}) to create full 10x3 grid\")\n\n    wandb.finish()\n\nif __name__ == \"__main__\":\n    evaluate_testset(\n        model_path='/kaggle/input/cnn/pytorch/default/1/best_model.pth',\n        test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val'\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:52:09.660844Z","iopub.execute_input":"2025-04-16T20:52:09.661084Z","iopub.status.idle":"2025-04-16T20:52:32.514117Z","shell.execute_reply.started":"2025-04-16T20:52:09.661064Z","shell.execute_reply":"2025-04-16T20:52:32.513510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T13:19:20.653819Z","iopub.execute_input":"2025-04-16T13:19:20.654444Z","iopub.status.idle":"2025-04-16T13:19:20.678407Z","shell.execute_reply.started":"2025-04-16T13:19:20.654419Z","shell.execute_reply":"2025-04-16T13:19:20.677809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport wandb\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\n\n\nclass OptimizedCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n\n        self.conv_blocks = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1),\n\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1),\n\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1),\n\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(3, stride=2, padding=1)\n        )\n\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n\ndef load_test_data(test_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val\", batch_size=256):\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n    dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n    return dataset, loader\n\n\ndef evaluate_best_model(best_model_path, test_loader, test_dataset, slider_index=0):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = OptimizedCNN(num_classes=len(test_dataset.classes)).to(device)\n    model.load_state_dict(torch.load(best_model_path, map_location=device))\n    model.eval()\n\n    correct = 0\n    total = 0\n    all_images, all_labels, all_preds = [], [], []\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n\n            total += labels.size(0)\n            correct += (preds == labels).sum().item()\n\n            all_images.extend(images.cpu())\n            all_labels.extend(labels.cpu())\n            all_preds.extend(preds.cpu())\n\n    test_accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n\n    return all_images, all_labels, all_preds, test_accuracy\n\n\ndef create_prediction_grid(images, labels, preds, class_names, slider_index=0):\n    \"\"\"Returns a 10x3 grid of images with predictions\"\"\"\n    random.seed(slider_index)\n    indices = random.sample(range(len(images)), 30)\n\n    fig, axes = plt.subplots(10, 3, figsize=(10, 25))\n    for i, ax in enumerate(axes.flat):\n        img = images[indices[i]].numpy().transpose((1, 2, 0))\n        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img = np.clip(img, 0, 1)\n        ax.imshow(img)\n        pred = class_names[preds[indices[i]]]\n        label = class_names[labels[indices[i]]]\n        title = f\"Pred: {pred}\\nTrue: {label}\"\n        ax.set_title(title, color='green' if pred == label else 'red', fontsize=8)\n        ax.axis('off')\n\n    plt.tight_layout()\n    img_path = f\"test_grid_{slider_index}.png\"\n    plt.savefig(img_path, dpi=300)\n    return img_path\n\n\ndef main(best_model_path, slider_index=0):\n    wandb.init(project=\"DL_A2\", name=f\"Test Evaluation - Grid {slider_index}\")\n\n    test_dataset, test_loader = load_test_data()\n    all_images, all_labels, all_preds, test_acc = evaluate_best_model(\n        best_model_path, test_loader, test_dataset, slider_index)\n\n    grid_path = create_prediction_grid(all_images, all_labels, all_preds, test_dataset.classes, slider_index)\n\n    wandb.log({\n        \"test_accuracy\": test_acc,\n        \"prediction_grid\": wandb.Image(grid_path),\n        \"grid_index\": slider_index\n    })\n    wandb.finish()\n\n\n# Call this with different slider values\nfor slider_index in range(0, 10):  # Slider index range from 0 to 9\n    main(best_model_path=\"/kaggle/input/cnn/pytorch/default/1/best_model.pth\", slider_index=slider_index)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:09:20.595528Z","iopub.execute_input":"2025-04-16T20:09:20.596189Z","iopub.status.idle":"2025-04-16T20:14:31.091275Z","shell.execute_reply.started":"2025-04-16T20:09:20.596161Z","shell.execute_reply":"2025-04-16T20:14:31.090589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom collections import defaultdict\nimport wandb\nimport random\nfrom PIL import Image\n\n# Load model architecture\nclass OptimizedCNN(torch.nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n        self.conv_blocks = torch.nn.Sequential(\n            torch.nn.Conv2d(3, 64, 7, 2, 3), torch.nn.BatchNorm2d(64), torch.nn.ReLU(), torch.nn.MaxPool2d(3, 2, 1),\n            torch.nn.Conv2d(64, 128, 5, padding=2), torch.nn.BatchNorm2d(128), torch.nn.ReLU(), torch.nn.MaxPool2d(3, 2, 1),\n            torch.nn.Conv2d(128, 256, 3, padding=1), torch.nn.BatchNorm2d(256), torch.nn.ReLU(), torch.nn.MaxPool2d(3, 2, 1),\n            torch.nn.Conv2d(256, 512, 3, padding=1), torch.nn.BatchNorm2d(512), torch.nn.ReLU(), torch.nn.MaxPool2d(3, 2, 1),\n            torch.nn.Conv2d(512, 512, 3, padding=1), torch.nn.BatchNorm2d(512), torch.nn.ReLU(), torch.nn.MaxPool2d(3, 2, 1)\n        )\n        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = torch.nn.Sequential(\n            torch.nn.Linear(512, 1024),\n            torch.nn.ReLU(),\n            torch.nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        return self.classifier(x)\n\n# Visualization Utility\ndef create_grid(images, labels, preds, class_names, title=\"Predictions\"):\n    fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n    for idx, ax in enumerate(axes.flat):\n        img = images[idx].numpy().transpose((1, 2, 0))\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        img = np.clip((img * std + mean), 0, 1)\n        ax.imshow(img)\n        ax.axis('off')\n        color = 'green' if preds[idx] == labels[idx] else 'red'\n        ax.set_title(f\"True: {class_names[labels[idx]]}\\nPred: {class_names[preds[idx]]}\", fontsize=8, color=color)\n    fig.suptitle(title, fontsize=16)\n    return fig\n\n# Main Evaluation\ndef evaluate_testset(model_path, test_dir, num_grids=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    loader = DataLoader(dataset, batch_size=256, shuffle=False, num_workers=4)\n    class_names = dataset.classes\n\n    model = OptimizedCNN(num_classes=len(class_names))\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Collect all predictions\n    all_images, all_labels, all_preds = [], [], []\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            outputs = model(images)\n            preds = torch.argmax(outputs, dim=1).cpu()\n            all_images.extend(images.cpu())\n            all_labels.extend(labels)\n            all_preds.extend(preds)\n\n    accuracy = 100 * np.mean(np.array(all_preds) == np.array(all_labels))\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    wandb.init(project=\"DL_A2\", name=\"evaluate_test\", job_type=\"test_eval\", reinit=True)\n\n    wandb.log({\"test_accuracy\": accuracy})\n\n    # Create random panels of 30 images (10x3) with slider\n    total = len(all_images)\n    slider_images = []\n    for i in range(num_grids):\n        indices = random.sample(range(total), 30)\n        sample_imgs = [all_images[j] for j in indices]\n        sample_labels = [all_labels[j] for j in indices]\n        sample_preds = [all_preds[j] for j in indices]\n\n        fig = create_grid(sample_imgs, sample_labels, sample_preds, class_names, title=f\"Random Grid {i+1}\")\n        grid_path = f\"panel_grid_{i}.png\"\n        fig.savefig(grid_path, dpi=300, bbox_inches='tight')\n        wandb.log({f\"prediction_panel_{i}\": wandb.Image(grid_path)})\n\n    # Panel section slider (index from 0 to 9)\n    wandb.log({\n        \"grid_slider\": wandb.Image(\"panel_grid_0.png\"),\n        \"index_slider\": wandb.Html('<input type=\"range\" min=\"0\" max=\"9\" value=\"0\" step=\"1\">')\n    })\n\n    wandb.finish()\n\n# Run\nif __name__ == \"__main__\":\n    evaluate_testset(\n        model_path='/kaggle/input/cnn/pytorch/default/1/best_model.pth',\n        test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val',\n        num_grids=10  # will generate 10 random 10×3 grids\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T20:00:15.942013Z","iopub.execute_input":"2025-04-16T20:00:15.942646Z","iopub.status.idle":"2025-04-16T20:02:33.774970Z","shell.execute_reply.started":"2025-04-16T20:00:15.942613Z","shell.execute_reply":"2025-04-16T20:02:33.773621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part B","metadata":{}},{"cell_type":"markdown","source":"## Question 5","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nimport wandb\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\n\n# ----------------------------\n# Data loading and preprocessing\n# ----------------------------\ndef get_dataloaders(data_dir, batch_size=64, val_split=0.2):\n    transform_train = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\n    transform_val = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=transform_train)\n    targets = np.array(full_dataset.targets)\n\n    # Stratified split\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n    val_dataset = torch.utils.data.Subset(datasets.ImageFolder(root=data_dir, transform=transform_val), val_idx)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n    return train_loader, val_loader, full_dataset.classes\n\n# ----------------------------\n# Fine-tune ViT model\n# ----------------------------\ndef build_model(num_classes=10):\n    model = models.vit_b_16(weights=\"IMAGENET1K_V1\")\n    model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n    return model\n\n# ----------------------------\n# Train and validate\n# ----------------------------\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=10):\n    model.to(device)\n    best_val_acc = 0.0\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, correct = 0, 0\n\n        for imgs, labels in train_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n\n        train_acc = correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_loss, val_correct = 0, 0\n        with torch.no_grad():\n            for imgs, labels in val_loader:\n                imgs, labels = imgs.to(device), labels.to(device)\n                outputs = model(imgs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(1) == labels).sum().item()\n\n        val_acc = val_correct / len(val_loader.dataset)\n        scheduler.step(val_loss)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": total_loss / len(train_loader),\n            \"val_loss\": val_loss / len(val_loader),\n            \"train_accuracy\": train_acc,\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n\n        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"vit_best_model.pth\")\n            print(f\" Saved new best model with val_acc = {best_val_acc:.4f}\")\n\n# ----------------------------\n# Main\n# ----------------------------\ndef main():\n    wandb.init(project=\"DL_A2\", name=\"ViT_model\")\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=64\n    )\n\n    model = build_model(num_classes=len(classes))\n\n    # Freeze all except classifier (optional)\n    for param in model.parameters():\n        param.requires_grad = False\n    for param in model.heads.parameters():\n        param.requires_grad = True\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=3)\n\n    train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=10)\n\n    wandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:07:27.962017Z","iopub.execute_input":"2025-04-17T05:07:27.962334Z","iopub.status.idle":"2025-04-17T05:07:27.978008Z","shell.execute_reply.started":"2025-04-17T05:07:27.962311Z","shell.execute_reply":"2025-04-17T05:07:27.977459Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:07:35.069473Z","iopub.execute_input":"2025-04-17T05:07:35.069722Z","iopub.status.idle":"2025-04-17T05:30:23.695184Z","shell.execute_reply.started":"2025-04-17T05:07:35.069705Z","shell.execute_reply":"2025-04-17T05:30:23.694593Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n100%|██████████| 330M/330M [00:01<00:00, 212MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc = 0.7223, Val Acc = 0.8430\n Saved new best model with val_acc = 0.8430\nEpoch 2: Train Acc = 0.7896, Val Acc = 0.8500\n Saved new best model with val_acc = 0.8500\nEpoch 3: Train Acc = 0.7981, Val Acc = 0.8590\n Saved new best model with val_acc = 0.8590\nEpoch 4: Train Acc = 0.8019, Val Acc = 0.8560\nEpoch 5: Train Acc = 0.8055, Val Acc = 0.8595\n Saved new best model with val_acc = 0.8595\nEpoch 6: Train Acc = 0.8099, Val Acc = 0.8565\nEpoch 7: Train Acc = 0.8074, Val Acc = 0.8575\nEpoch 8: Train Acc = 0.8107, Val Acc = 0.8600\n Saved new best model with val_acc = 0.8600\nEpoch 9: Train Acc = 0.8159, Val Acc = 0.8590\nEpoch 10: Train Acc = 0.8117, Val Acc = 0.8520\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█▇███</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄█▆█▇▇██▅</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>0.81173</td></tr><tr><td>train_loss</td><td>0.59423</td></tr><tr><td>val_accuracy</td><td>0.852</td></tr><tr><td>val_loss</td><td>0.47472</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wild-snowflake-1</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2_ViT_Finetune/runs/yf4vtav7' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2_ViT_Finetune/runs/yf4vtav7</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2_ViT_Finetune' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2_ViT_Finetune</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_050613-yf4vtav7/logs</code>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Frozen Feature Extractor","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nimport wandb\n\n# Initialize WandB\nwandb.init(project=\"DL_A2\",name=\"inaturalist-finetuning\", config={\n    \"strategy\": \"Frozen Feature Extractor\",\n    \"architecture\": \"ResNet50\"\n})\n\n# Data Transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load Data\ntrain_data = datasets.ImageFolder('/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train', transform=train_transform)\nval_data = datasets.ImageFolder('/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val', transform=val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=64)\n\n# Model Setup\nmodel = models.resnet50(weights='IMAGENET1K_V2')\n\n# Freeze all layers\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer\nmodel.fc = nn.Linear(model.fc.in_features, len(train_data.classes))\n\n# Training Config\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n\n# Training Loop\nfor epoch in range(10):\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n    # Validation\n    model.eval()\n    val_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            preds = outputs.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n    \n    val_acc = 100 * correct / len(val_data)\n    \n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": loss.item(),\n        \"val_loss\": val_loss/len(val_loader),\n        \"val_acc\": val_acc\n    })\n\ntorch.save(model.state_dict(), \"finetuned_resnet50.pth\")\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T12:20:26.444163Z","iopub.execute_input":"2025-04-17T12:20:26.444390Z","iopub.status.idle":"2025-04-17T12:46:48.170031Z","shell.execute_reply.started":"2025-04-17T12:20:26.444367Z","shell.execute_reply":"2025-04-17T12:46:48.169493Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250417_122026-y0enn8c9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/y0enn8c9' target=\"_blank\">inaturalist-finetuning</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/y0enn8c9' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/y0enn8c9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>▇█▄▆▂▃▅▅█▁</td></tr><tr><td>val_acc</td><td>▁▅▅▆▇▇█▇██</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_loss</td><td>0.34243</td></tr><tr><td>val_acc</td><td>84.45</td></tr><tr><td>val_loss</td><td>0.50303</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">inaturalist-finetuning</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/y0enn8c9' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/y0enn8c9</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_122026-y0enn8c9/logs</code>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/","metadata":{}},{"cell_type":"markdown","source":"Progressive Unfreezing (Bottom-Up)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader\nimport wandb\n\n# Initialize WandB\nwandb.init(project=\"DL_A2\",name=\"inaturalist-progressive-unfreeze\", config={\n    \"strategy\": \"Progressive Unfreezing (Bottom-Up)\",\n    \"architecture\": \"ResNet50\"\n})\n\n# Data Transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(0.2, 0.2, 0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize(256),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Load Data\ntrain_data = datasets.ImageFolder('/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train', transform=train_transform)\nval_data = datasets.ImageFolder('/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val', transform=val_transform)\n\ntrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_data, batch_size=64, num_workers=4)\n\n# Model Setup\nmodel = models.resnet50(weights='IMAGENET1K_V2')\n\n# Freeze all layers initially\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer\nmodel.fc = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(model.fc.in_features, 256),\n    nn.ReLU(),\n    nn.Linear(256, len(train_data.classes))\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training Config\noptimizer = optim.Adam([\n    {'params': model.fc.parameters(), 'lr': 1e-3}\n])\ncriterion = nn.CrossEntropyLoss()\n\n# Progressive Unfreezing Schedule\nunfreeze_schedule = {\n    3: ['layer4'],    # Unfreeze layer4 after 3 epochs\n    6: ['layer3'],    # Unfreeze layer3 after 6 epochs\n    9: ['layer2']     # Unfreeze layer2 after 9 epochs\n}\n\nfor epoch in range(15):\n    # Check unfreezing condition\n    if epoch in unfreeze_schedule:\n        for layer_name in unfreeze_schedule[epoch]:\n            for name, param in model.named_parameters():\n                if layer_name in name:\n                    param.requires_grad = True\n            print(f\"Unfrozen {layer_name}\")\n            \n            # Add to optimizer with lower LR\n            new_params = [p for n,p in model.named_parameters() \n                         if layer_name in n and p.requires_grad]\n            optimizer.add_param_group({\n                'params': new_params,\n                'lr': 1e-4 * (0.1 ** (epoch//3))  # Decreasing LR\n            })\n    \n    # Training\n    model.train()\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n    \n    # Validation\n    model.eval()\n    val_loss, correct = 0, 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            val_loss += criterion(outputs, labels).item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n    \n    val_acc = 100 * correct / len(val_data)\n    \n    wandb.log({\n        \"epoch\": epoch,\n        \"train_loss\": loss.item(),\n        \"val_loss\": val_loss/len(val_loader),\n        \"val_acc\": val_acc,\n        \"lr_fc\": optimizer.param_groups[0]['lr'],\n        \"lr_layer4\": optimizer.param_groups[1]['lr'] if len(optimizer.param_groups)>1 else 0\n    })\n\ntorch.save(model.state_dict(), \"progressive_unfreeze_resnet50.pth\")\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T11:59:17.689857Z","iopub.execute_input":"2025-04-17T11:59:17.690157Z","iopub.status.idle":"2025-04-17T12:20:26.442778Z","shell.execute_reply.started":"2025-04-17T11:59:17.690136Z","shell.execute_reply":"2025-04-17T12:20:26.442132Z"}},"outputs":[{"name":"stdout","text":"Unfrozen layer4\nUnfrozen layer3\nUnfrozen layer2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>lr_fc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_layer4</td><td>▁▁▁████████████</td></tr><tr><td>train_loss</td><td>▅▆▆█▇▅█▆█▆▆▆▆▁▄▂▃▅</td></tr><tr><td>val_acc</td><td>▁▃▄▃▄▄▅▆▇▇▇▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▄▅▄▄▃▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>lr_fc</td><td>0.001</td></tr><tr><td>lr_layer4</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.8123</td></tr><tr><td>val_acc</td><td>86.95</td></tr><tr><td>val_loss</td><td>0.38761</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">inaturalist-finetuning</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lg6boqkz' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/lg6boqkz</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250417_114604-lg6boqkz/logs</code>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\n# ------------------------ Sweep Config ------------------------ #\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"augment\": {\"values\": [True, False]},\n        \"batch_size\": {\"values\": [64, 256]},\n        \"lr\": {\"values\": [0.01, 0.001]},\n        \"epochs\": {\"value\": 10}\n    }\n}\n\n\n# ------------------------ Data Loader ------------------------ #\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(0.2, 0.2, 0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    targets = np.array(full_dataset.targets)\n\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n    return train_loader, val_loader, full_dataset.classes\n\n\n# ------------------------ Training Function ------------------------ #\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=30):\n    model.to(device)\n    best_val_acc = 0\n\n    for epoch in range(epochs):\n        # Progressive Unfreezing\n        if epoch == 5:\n            for name, param in model.named_parameters():\n                if \"encoder.layer.10\" in name or \"encoder.layer.11\" in name:\n                    param.requires_grad = True\n\n        model.train()\n        train_loss, correct = 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n            out = model(x)\n            loss = criterion(out, y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            correct += (out.argmax(1) == y).sum().item()\n        train_acc = 100. * correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_loss, val_correct = 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n                loss = criterion(out, y)\n                val_loss += loss.item()\n                val_correct += (out.argmax(1) == y).sum().item()\n        val_acc = 100. * val_correct / len(val_loader.dataset)\n        scheduler.step(val_loss)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n\n        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"best_model_vit.pth\")\n\n    return best_val_acc\n\n\n# ------------------------ Main Function ------------------------ #\ndef main():\n    wandb.init(project=\"DL_A2\")\n    config = wandb.config\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=config.batch_size,\n        augment=config.augment\n    )\n\n    # Load pre-trained ViT\n    vit = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n\n    # Freeze all layers first\n    for param in vit.parameters():\n        param.requires_grad = False\n\n    # Replace classifier head\n    in_features = vit.heads[0].in_features\n    vit.heads = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, len(classes))\n    )\n\n    # Enable training on new head\n    for param in vit.heads.parameters():\n        param.requires_grad = True\n\n    optimizer = optim.SGD(vit.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    criterion = nn.CrossEntropyLoss()\n\n    best_val_acc = train(\n        model=vit,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        optimizer=optimizer,\n        criterion=criterion,\n        scheduler=scheduler,\n        device=device,\n        epochs=config.epochs\n    )\n\n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n\n# ------------------------ Start Sweep ------------------------ #\nsweep_id = wandb.sweep(sweep_config, project=\"DL_A2\")\nwandb.agent(sweep_id, function=main, count=20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T03:27:04.637538Z","iopub.execute_input":"2025-04-18T03:27:04.638131Z","iopub.status.idle":"2025-04-18T12:08:22.433022Z","shell.execute_reply.started":"2025-04-18T03:27:04.638102Z","shell.execute_reply":"2025-04-18T12:08:22.432204Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: w0wfeap0\nSweep URL: https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 23i3wyb0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_032711-23i3wyb0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/23i3wyb0' target=\"_blank\">ethereal-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/23i3wyb0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/23i3wyb0</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 45.73%, Val Acc: 72.05%\nEpoch 2: Train Acc: 76.27%, Val Acc: 81.25%\nEpoch 3: Train Acc: 81.14%, Val Acc: 83.50%\nEpoch 4: Train Acc: 83.09%, Val Acc: 84.15%\nEpoch 5: Train Acc: 83.97%, Val Acc: 84.45%\nEpoch 6: Train Acc: 84.57%, Val Acc: 84.75%\nEpoch 7: Train Acc: 84.82%, Val Acc: 84.90%\nEpoch 8: Train Acc: 85.61%, Val Acc: 85.30%\nEpoch 9: Train Acc: 86.05%, Val Acc: 85.30%\nEpoch 10: Train Acc: 86.41%, Val Acc: 85.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>85.35</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>86.4108</td></tr><tr><td>train_loss</td><td>0.4941</td></tr><tr><td>val_accuracy</td><td>85.35</td></tr><tr><td>val_loss</td><td>0.51933</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ethereal-sweep-1</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/23i3wyb0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/23i3wyb0</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_032711-23i3wyb0/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a1bwgbh4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_035235-a1bwgbh4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/a1bwgbh4' target=\"_blank\">divine-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/a1bwgbh4' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/a1bwgbh4</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 14.41%, Val Acc: 31.30%\nEpoch 2: Train Acc: 36.34%, Val Acc: 58.90%\nEpoch 3: Train Acc: 54.43%, Val Acc: 69.45%\nEpoch 4: Train Acc: 63.91%, Val Acc: 74.60%\nEpoch 5: Train Acc: 69.08%, Val Acc: 77.50%\nEpoch 6: Train Acc: 71.52%, Val Acc: 79.10%\nEpoch 7: Train Acc: 72.07%, Val Acc: 79.80%\nEpoch 8: Train Acc: 73.68%, Val Acc: 80.55%\nEpoch 9: Train Acc: 74.66%, Val Acc: 80.95%\nEpoch 10: Train Acc: 76.13%, Val Acc: 81.55%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>81.55</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>76.13452</td></tr><tr><td>train_loss</td><td>1.18125</td></tr><tr><td>val_accuracy</td><td>81.55</td></tr><tr><td>val_loss</td><td>1.0794</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">divine-sweep-2</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/a1bwgbh4' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/a1bwgbh4</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_035235-a1bwgbh4/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhksj3yq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_041914-bhksj3yq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/bhksj3yq' target=\"_blank\">frosty-sweep-3</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/bhksj3yq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/bhksj3yq</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 13.19%, Val Acc: 30.05%\nEpoch 2: Train Acc: 37.14%, Val Acc: 57.30%\nEpoch 3: Train Acc: 54.73%, Val Acc: 67.85%\nEpoch 4: Train Acc: 64.32%, Val Acc: 73.45%\nEpoch 5: Train Acc: 67.60%, Val Acc: 76.25%\nEpoch 6: Train Acc: 71.12%, Val Acc: 79.10%\nEpoch 7: Train Acc: 73.37%, Val Acc: 80.15%\nEpoch 8: Train Acc: 74.65%, Val Acc: 81.05%\nEpoch 9: Train Acc: 74.65%, Val Acc: 81.75%\nEpoch 10: Train Acc: 76.02%, Val Acc: 82.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>82.25</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>76.022</td></tr><tr><td>train_loss</td><td>1.17054</td></tr><tr><td>val_accuracy</td><td>82.25</td></tr><tr><td>val_loss</td><td>1.06778</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">frosty-sweep-3</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/bhksj3yq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/bhksj3yq</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_041914-bhksj3yq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 12vxj77x with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_044553-12vxj77x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/12vxj77x' target=\"_blank\">warm-sweep-4</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/12vxj77x' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/12vxj77x</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 47.69%, Val Acc: 80.50%\nEpoch 2: Train Acc: 76.25%, Val Acc: 82.30%\nEpoch 3: Train Acc: 78.21%, Val Acc: 84.30%\nEpoch 4: Train Acc: 79.47%, Val Acc: 84.75%\nEpoch 5: Train Acc: 80.26%, Val Acc: 84.95%\nEpoch 6: Train Acc: 80.59%, Val Acc: 85.10%\nEpoch 7: Train Acc: 81.21%, Val Acc: 85.45%\nEpoch 8: Train Acc: 81.54%, Val Acc: 85.75%\nEpoch 9: Train Acc: 81.84%, Val Acc: 85.75%\nEpoch 10: Train Acc: 82.39%, Val Acc: 86.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.1</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>82.3853</td></tr><tr><td>train_loss</td><td>0.57101</td></tr><tr><td>val_accuracy</td><td>86.1</td></tr><tr><td>val_loss</td><td>0.46575</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-sweep-4</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/12vxj77x' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/12vxj77x</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_044553-12vxj77x/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4iygpx6d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_051237-4iygpx6d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4iygpx6d' target=\"_blank\">still-sweep-5</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4iygpx6d' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4iygpx6d</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 42.32%, Val Acc: 73.45%\nEpoch 2: Train Acc: 70.57%, Val Acc: 81.00%\nEpoch 3: Train Acc: 75.73%, Val Acc: 82.30%\nEpoch 4: Train Acc: 76.90%, Val Acc: 83.40%\nEpoch 5: Train Acc: 77.53%, Val Acc: 84.20%\nEpoch 6: Train Acc: 78.97%, Val Acc: 84.20%\nEpoch 7: Train Acc: 78.78%, Val Acc: 84.30%\nEpoch 8: Train Acc: 79.17%, Val Acc: 84.85%\nEpoch 9: Train Acc: 79.58%, Val Acc: 84.75%\nEpoch 10: Train Acc: 79.68%, Val Acc: 84.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▆▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>84.85</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>79.68496</td></tr><tr><td>train_loss</td><td>0.6705</td></tr><tr><td>val_accuracy</td><td>84.7</td></tr><tr><td>val_loss</td><td>0.5439</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">still-sweep-5</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4iygpx6d' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4iygpx6d</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_051237-4iygpx6d/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yzgv9d3e with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_053811-yzgv9d3e</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/yzgv9d3e' target=\"_blank\">earnest-sweep-6</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/yzgv9d3e' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/yzgv9d3e</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 51.27%, Val Acc: 80.30%\nEpoch 2: Train Acc: 82.09%, Val Acc: 83.60%\nEpoch 3: Train Acc: 84.37%, Val Acc: 84.80%\nEpoch 4: Train Acc: 86.02%, Val Acc: 85.15%\nEpoch 5: Train Acc: 86.77%, Val Acc: 85.35%\nEpoch 6: Train Acc: 87.64%, Val Acc: 85.70%\nEpoch 7: Train Acc: 88.54%, Val Acc: 85.95%\nEpoch 8: Train Acc: 89.60%, Val Acc: 86.05%\nEpoch 9: Train Acc: 89.59%, Val Acc: 86.50%\nEpoch 10: Train Acc: 90.12%, Val Acc: 86.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.5</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>90.12377</td></tr><tr><td>train_loss</td><td>0.33415</td></tr><tr><td>val_accuracy</td><td>86.25</td></tr><tr><td>val_loss</td><td>0.45406</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earnest-sweep-6</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/yzgv9d3e' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/yzgv9d3e</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_053811-yzgv9d3e/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 59zknbis with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_060430-59zknbis</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/59zknbis' target=\"_blank\">gallant-sweep-7</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/59zknbis' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/59zknbis</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 69.30%, Val Acc: 84.30%\nEpoch 2: Train Acc: 80.05%, Val Acc: 86.05%\nEpoch 3: Train Acc: 81.25%, Val Acc: 86.55%\nEpoch 4: Train Acc: 82.89%, Val Acc: 86.70%\nEpoch 5: Train Acc: 82.81%, Val Acc: 87.10%\nEpoch 6: Train Acc: 83.91%, Val Acc: 87.30%\nEpoch 7: Train Acc: 84.31%, Val Acc: 87.55%\nEpoch 8: Train Acc: 85.17%, Val Acc: 87.35%\nEpoch 9: Train Acc: 85.67%, Val Acc: 87.70%\nEpoch 10: Train Acc: 86.30%, Val Acc: 87.85%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.85</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>86.29829</td></tr><tr><td>train_loss</td><td>0.42413</td></tr><tr><td>val_accuracy</td><td>87.85</td></tr><tr><td>val_loss</td><td>0.38344</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">gallant-sweep-7</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/59zknbis' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/59zknbis</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_060430-59zknbis/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6bgdkzeg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_063003-6bgdkzeg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/6bgdkzeg' target=\"_blank\">devoted-sweep-8</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/6bgdkzeg' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/6bgdkzeg</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 69.35%, Val Acc: 84.95%\nEpoch 2: Train Acc: 79.83%, Val Acc: 85.50%\nEpoch 3: Train Acc: 81.31%, Val Acc: 86.05%\nEpoch 4: Train Acc: 82.39%, Val Acc: 86.70%\nEpoch 5: Train Acc: 82.85%, Val Acc: 86.55%\nEpoch 6: Train Acc: 84.06%, Val Acc: 87.15%\nEpoch 7: Train Acc: 84.46%, Val Acc: 87.10%\nEpoch 8: Train Acc: 84.66%, Val Acc: 87.35%\nEpoch 9: Train Acc: 85.61%, Val Acc: 86.90%\nEpoch 10: Train Acc: 85.75%, Val Acc: 87.65%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▆▅▇▇▇▆█</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.65</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>85.74822</td></tr><tr><td>train_loss</td><td>0.42192</td></tr><tr><td>val_accuracy</td><td>87.65</td></tr><tr><td>val_loss</td><td>0.39498</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">devoted-sweep-8</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/6bgdkzeg' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/6bgdkzeg</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_063003-6bgdkzeg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1mxu3mmd with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_065532-1mxu3mmd</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/1mxu3mmd' target=\"_blank\">iconic-sweep-9</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/1mxu3mmd' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/1mxu3mmd</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 51.38%, Val Acc: 80.30%\nEpoch 2: Train Acc: 81.76%, Val Acc: 83.35%\nEpoch 3: Train Acc: 84.30%, Val Acc: 84.45%\nEpoch 4: Train Acc: 85.49%, Val Acc: 84.90%\nEpoch 5: Train Acc: 86.56%, Val Acc: 85.45%\nEpoch 6: Train Acc: 87.74%, Val Acc: 85.70%\nEpoch 7: Train Acc: 88.60%, Val Acc: 85.90%\nEpoch 8: Train Acc: 89.07%, Val Acc: 86.65%\nEpoch 9: Train Acc: 89.84%, Val Acc: 86.95%\nEpoch 10: Train Acc: 90.32%, Val Acc: 87.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.1</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>90.32379</td></tr><tr><td>train_loss</td><td>0.33331</td></tr><tr><td>val_accuracy</td><td>87.1</td></tr><tr><td>val_loss</td><td>0.44397</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">iconic-sweep-9</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/1mxu3mmd' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/1mxu3mmd</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_065532-1mxu3mmd/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zz5dyyg0 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_072147-zz5dyyg0</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zz5dyyg0' target=\"_blank\">confused-sweep-10</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zz5dyyg0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zz5dyyg0</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 52.91%, Val Acc: 80.50%\nEpoch 2: Train Acc: 81.89%, Val Acc: 84.30%\nEpoch 3: Train Acc: 84.34%, Val Acc: 84.70%\nEpoch 4: Train Acc: 85.75%, Val Acc: 85.05%\nEpoch 5: Train Acc: 86.75%, Val Acc: 85.40%\nEpoch 6: Train Acc: 87.76%, Val Acc: 85.65%\nEpoch 7: Train Acc: 88.55%, Val Acc: 85.65%\nEpoch 8: Train Acc: 89.01%, Val Acc: 85.65%\nEpoch 9: Train Acc: 89.52%, Val Acc: 86.25%\nEpoch 10: Train Acc: 90.07%, Val Acc: 86.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▆▇▇▇▇▇██</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.25</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>90.07376</td></tr><tr><td>train_loss</td><td>0.33829</td></tr><tr><td>val_accuracy</td><td>86.05</td></tr><tr><td>val_loss</td><td>0.45322</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">confused-sweep-10</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zz5dyyg0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/zz5dyyg0</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_072147-zz5dyyg0/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o8am6wd8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_074759-o8am6wd8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/o8am6wd8' target=\"_blank\">blooming-sweep-11</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/o8am6wd8' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/o8am6wd8</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 40.71%, Val Acc: 73.60%\nEpoch 2: Train Acc: 71.02%, Val Acc: 80.50%\nEpoch 3: Train Acc: 74.58%, Val Acc: 82.35%\nEpoch 4: Train Acc: 76.71%, Val Acc: 83.15%\nEpoch 5: Train Acc: 78.13%, Val Acc: 83.75%\nEpoch 6: Train Acc: 78.16%, Val Acc: 83.80%\nEpoch 7: Train Acc: 78.20%, Val Acc: 84.10%\nEpoch 8: Train Acc: 79.71%, Val Acc: 84.55%\nEpoch 9: Train Acc: 79.40%, Val Acc: 84.60%\nEpoch 10: Train Acc: 79.26%, Val Acc: 84.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>84.7</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>79.25991</td></tr><tr><td>train_loss</td><td>0.68659</td></tr><tr><td>val_accuracy</td><td>84.7</td></tr><tr><td>val_loss</td><td>0.54984</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">blooming-sweep-11</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/o8am6wd8' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/o8am6wd8</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_074759-o8am6wd8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0406a3zu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_081331-0406a3zu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0406a3zu' target=\"_blank\">happy-sweep-12</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0406a3zu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0406a3zu</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 17.24%, Val Acc: 35.00%\nEpoch 2: Train Acc: 41.94%, Val Acc: 56.40%\nEpoch 3: Train Acc: 59.58%, Val Acc: 69.40%\nEpoch 4: Train Acc: 68.47%, Val Acc: 74.70%\nEpoch 5: Train Acc: 73.85%, Val Acc: 77.65%\nEpoch 6: Train Acc: 76.81%, Val Acc: 79.25%\nEpoch 7: Train Acc: 79.65%, Val Acc: 79.55%\nEpoch 8: Train Acc: 80.05%, Val Acc: 80.25%\nEpoch 9: Train Acc: 81.75%, Val Acc: 81.05%\nEpoch 10: Train Acc: 81.66%, Val Acc: 81.55%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>81.55</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>81.66021</td></tr><tr><td>train_loss</td><td>1.07035</td></tr><tr><td>val_accuracy</td><td>81.55</td></tr><tr><td>val_loss</td><td>1.02605</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">happy-sweep-12</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0406a3zu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/0406a3zu</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_081331-0406a3zu/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 61ubh9lp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_083945-61ubh9lp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/61ubh9lp' target=\"_blank\">earnest-sweep-13</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/61ubh9lp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/61ubh9lp</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 13.75%, Val Acc: 29.95%\nEpoch 2: Train Acc: 35.48%, Val Acc: 55.30%\nEpoch 3: Train Acc: 54.39%, Val Acc: 68.40%\nEpoch 4: Train Acc: 63.16%, Val Acc: 74.55%\nEpoch 5: Train Acc: 69.00%, Val Acc: 77.25%\nEpoch 6: Train Acc: 71.68%, Val Acc: 79.45%\nEpoch 7: Train Acc: 72.52%, Val Acc: 80.20%\nEpoch 8: Train Acc: 73.81%, Val Acc: 81.30%\nEpoch 9: Train Acc: 75.61%, Val Acc: 82.00%\nEpoch 10: Train Acc: 75.40%, Val Acc: 82.20%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>82.2</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>75.39692</td></tr><tr><td>train_loss</td><td>1.17337</td></tr><tr><td>val_accuracy</td><td>82.2</td></tr><tr><td>val_loss</td><td>1.07479</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">earnest-sweep-13</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/61ubh9lp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/61ubh9lp</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_083945-61ubh9lp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vli9wcvg with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_090621-vli9wcvg</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/vli9wcvg' target=\"_blank\">effortless-sweep-14</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/vli9wcvg' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/vli9wcvg</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 14.91%, Val Acc: 33.75%\nEpoch 2: Train Acc: 37.62%, Val Acc: 58.70%\nEpoch 3: Train Acc: 55.99%, Val Acc: 69.50%\nEpoch 4: Train Acc: 63.86%, Val Acc: 74.25%\nEpoch 5: Train Acc: 68.53%, Val Acc: 76.85%\nEpoch 6: Train Acc: 71.05%, Val Acc: 78.80%\nEpoch 7: Train Acc: 73.65%, Val Acc: 79.20%\nEpoch 8: Train Acc: 74.25%, Val Acc: 80.20%\nEpoch 9: Train Acc: 75.21%, Val Acc: 81.15%\nEpoch 10: Train Acc: 75.78%, Val Acc: 81.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>81.7</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>75.78447</td></tr><tr><td>train_loss</td><td>1.16571</td></tr><tr><td>val_accuracy</td><td>81.7</td></tr><tr><td>val_loss</td><td>1.06896</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">effortless-sweep-14</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/vli9wcvg' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/vli9wcvg</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_090621-vli9wcvg/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4jn2jijl with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_093253-4jn2jijl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4jn2jijl' target=\"_blank\">polished-sweep-15</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4jn2jijl' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4jn2jijl</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 44.26%, Val Acc: 73.75%\nEpoch 2: Train Acc: 71.12%, Val Acc: 80.70%\nEpoch 3: Train Acc: 74.97%, Val Acc: 82.45%\nEpoch 4: Train Acc: 76.50%, Val Acc: 83.25%\nEpoch 5: Train Acc: 78.00%, Val Acc: 84.15%\nEpoch 6: Train Acc: 78.45%, Val Acc: 84.65%\nEpoch 7: Train Acc: 78.70%, Val Acc: 84.90%\nEpoch 8: Train Acc: 79.20%, Val Acc: 84.95%\nEpoch 9: Train Acc: 79.91%, Val Acc: 84.75%\nEpoch 10: Train Acc: 80.15%, Val Acc: 85.40%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>85.4</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>80.14752</td></tr><tr><td>train_loss</td><td>0.67872</td></tr><tr><td>val_accuracy</td><td>85.4</td></tr><tr><td>val_loss</td><td>0.54554</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">polished-sweep-15</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4jn2jijl' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4jn2jijl</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_093253-4jn2jijl/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p5rw2eps with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_095827-p5rw2eps</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/p5rw2eps' target=\"_blank\">glamorous-sweep-16</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/p5rw2eps' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/p5rw2eps</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 74.35%, Val Acc: 85.10%\nEpoch 2: Train Acc: 87.01%, Val Acc: 85.75%\nEpoch 3: Train Acc: 89.20%, Val Acc: 86.50%\nEpoch 4: Train Acc: 91.20%, Val Acc: 86.60%\nEpoch 5: Train Acc: 92.42%, Val Acc: 86.50%\nEpoch 6: Train Acc: 93.74%, Val Acc: 87.00%\nEpoch 7: Train Acc: 95.05%, Val Acc: 87.15%\nEpoch 8: Train Acc: 96.16%, Val Acc: 87.00%\nEpoch 9: Train Acc: 97.05%, Val Acc: 86.90%\nEpoch 10: Train Acc: 97.42%, Val Acc: 86.95%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>███████▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▆▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▆▇█▇▇▇</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.15</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>97.42468</td></tr><tr><td>train_loss</td><td>0.11205</td></tr><tr><td>val_accuracy</td><td>86.95</td></tr><tr><td>val_loss</td><td>0.44287</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">glamorous-sweep-16</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/p5rw2eps' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/p5rw2eps</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_095827-p5rw2eps/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 87kmqdhx with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_102350-87kmqdhx</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/87kmqdhx' target=\"_blank\">whole-sweep-17</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/87kmqdhx' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/87kmqdhx</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 48.12%, Val Acc: 79.70%\nEpoch 2: Train Acc: 75.92%, Val Acc: 82.80%\nEpoch 3: Train Acc: 78.25%, Val Acc: 83.65%\nEpoch 4: Train Acc: 79.10%, Val Acc: 84.40%\nEpoch 5: Train Acc: 79.68%, Val Acc: 84.85%\nEpoch 6: Train Acc: 80.84%, Val Acc: 85.25%\nEpoch 7: Train Acc: 81.34%, Val Acc: 85.75%\nEpoch 8: Train Acc: 81.39%, Val Acc: 85.80%\nEpoch 9: Train Acc: 81.46%, Val Acc: 86.35%\nEpoch 10: Train Acc: 82.15%, Val Acc: 86.15%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.35</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>82.14777</td></tr><tr><td>train_loss</td><td>0.57153</td></tr><tr><td>val_accuracy</td><td>86.15</td></tr><tr><td>val_loss</td><td>0.46555</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">whole-sweep-17</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/87kmqdhx' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/87kmqdhx</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_102350-87kmqdhx/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7tgxxcw3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_105021-7tgxxcw3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/7tgxxcw3' target=\"_blank\">valiant-sweep-18</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/7tgxxcw3' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/7tgxxcw3</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 74.62%, Val Acc: 84.70%\nEpoch 2: Train Acc: 86.90%, Val Acc: 85.50%\nEpoch 3: Train Acc: 89.34%, Val Acc: 86.30%\nEpoch 4: Train Acc: 91.05%, Val Acc: 86.95%\nEpoch 5: Train Acc: 92.87%, Val Acc: 87.10%\nEpoch 6: Train Acc: 93.94%, Val Acc: 87.00%\nEpoch 7: Train Acc: 95.12%, Val Acc: 87.05%\nEpoch 8: Train Acc: 96.20%, Val Acc: 87.00%\nEpoch 9: Train Acc: 96.86%, Val Acc: 86.70%\nEpoch 10: Train Acc: 97.90%, Val Acc: 87.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>████████▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆█████▇█</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.1</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>97.89974</td></tr><tr><td>train_loss</td><td>0.09434</td></tr><tr><td>val_accuracy</td><td>87</td></tr><tr><td>val_loss</td><td>0.45085</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">valiant-sweep-18</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/7tgxxcw3' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/7tgxxcw3</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_105021-7tgxxcw3/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: onvjckzq with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_111544-onvjckzq</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/onvjckzq' target=\"_blank\">floral-sweep-19</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/onvjckzq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/onvjckzq</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 46.97%, Val Acc: 80.40%\nEpoch 2: Train Acc: 75.12%, Val Acc: 82.85%\nEpoch 3: Train Acc: 77.75%, Val Acc: 83.90%\nEpoch 4: Train Acc: 78.41%, Val Acc: 84.55%\nEpoch 5: Train Acc: 80.34%, Val Acc: 85.25%\nEpoch 6: Train Acc: 80.64%, Val Acc: 85.35%\nEpoch 7: Train Acc: 81.04%, Val Acc: 85.75%\nEpoch 8: Train Acc: 82.05%, Val Acc: 85.75%\nEpoch 9: Train Acc: 81.41%, Val Acc: 85.90%\nEpoch 10: Train Acc: 82.59%, Val Acc: 86.15%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.15</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>82.58532</td></tr><tr><td>train_loss</td><td>0.56197</td></tr><tr><td>val_accuracy</td><td>86.15</td></tr><tr><td>val_loss</td><td>0.45918</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">floral-sweep-19</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/onvjckzq' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/onvjckzq</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_111544-onvjckzq/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4fobcav1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_114219-4fobcav1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4fobcav1' target=\"_blank\">youthful-sweep-20</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/w0wfeap0</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4fobcav1' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4fobcav1</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 50.94%, Val Acc: 80.00%\nEpoch 2: Train Acc: 81.36%, Val Acc: 83.35%\nEpoch 3: Train Acc: 84.15%, Val Acc: 84.30%\nEpoch 4: Train Acc: 85.95%, Val Acc: 85.25%\nEpoch 5: Train Acc: 86.80%, Val Acc: 85.70%\nEpoch 6: Train Acc: 87.82%, Val Acc: 85.80%\nEpoch 7: Train Acc: 88.50%, Val Acc: 86.15%\nEpoch 8: Train Acc: 89.25%, Val Acc: 86.20%\nEpoch 9: Train Acc: 89.86%, Val Acc: 86.35%\nEpoch 10: Train Acc: 90.22%, Val Acc: 86.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.35</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>90.22378</td></tr><tr><td>train_loss</td><td>0.33171</td></tr><tr><td>val_accuracy</td><td>86.35</td></tr><tr><td>val_loss</td><td>0.45207</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">youthful-sweep-20</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4fobcav1' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/4fobcav1</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_114219-4fobcav1/logs</code>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\n# ------------------------ Sweep Config ------------------------ #\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"augment\": {\"values\": [True, False]},\n        \"batch_size\": {\"values\": [64, 256]},\n        \"lr\": {\"values\": [0.01, 0.001]},\n        \"epochs\": {\"value\": 10}\n    }\n}\n\n\n# ------------------------ Data Loader ------------------------ #\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(0.2, 0.2, 0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    targets = np.array(full_dataset.targets)\n\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n    return train_loader, val_loader, full_dataset.classes\n\n\n# ------------------------ Training Function ------------------------ #\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=30):\n    model.to(device)\n    best_val_acc = 0\n\n    for epoch in range(epochs):\n        # Progressive Unfreezing\n        if epoch == 5:\n            for name, param in model.named_parameters():\n                if \"encoder.layer.10\" in name or \"encoder.layer.11\" in name:\n                    param.requires_grad = True\n\n        model.train()\n        train_loss, correct = 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n            out = model(x)\n            loss = criterion(out, y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            correct += (out.argmax(1) == y).sum().item()\n        train_acc = 100. * correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_loss, val_correct = 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n                loss = criterion(out, y)\n                val_loss += loss.item()\n                val_correct += (out.argmax(1) == y).sum().item()\n        val_acc = 100. * val_correct / len(val_loader.dataset)\n        scheduler.step(val_loss)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n\n        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"best_model_vit.pth\")\n\n    return best_val_acc\n\n\n# ------------------------ Main Function ------------------------ #\ndef main():\n    wandb.init(project=\"DL_A2\")\n    config = wandb.config\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=config.batch_size,\n        augment=config.augment\n    )\n\n    # Load pre-trained ViT\n    vit = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n\n    # Freeze all layers first\n    for param in vit.parameters():\n        param.requires_grad = False\n\n    # Replace classifier head\n    in_features = vit.heads[0].in_features\n    vit.heads = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, len(classes))\n    )\n\n    # Enable training on new head\n    for param in vit.heads.parameters():\n        param.requires_grad = True\n\n    optimizer = optim.SGD(vit.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    criterion = nn.CrossEntropyLoss()\n\n    best_val_acc = train(\n        model=vit,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        optimizer=optimizer,\n        criterion=criterion,\n        scheduler=scheduler,\n        device=device,\n        epochs=config.epochs\n    )\n\n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:23:40.640515Z","iopub.execute_input":"2025-04-18T13:23:40.640829Z","iopub.status.idle":"2025-04-18T13:23:48.850927Z","shell.execute_reply.started":"2025-04-18T13:23:40.640806Z","shell.execute_reply":"2025-04-18T13:23:48.850174Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ------------------------ Start Sweep ------------------------ #\nsweep_id = wandb.sweep(sweep_config, project=\"DL_A2\")\nwandb.agent(sweep_id, function=main, count=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:23:48.852053Z","iopub.execute_input":"2025-04-18T13:23:48.852514Z","iopub.status.idle":"2025-04-18T14:30:32.070084Z","shell.execute_reply.started":"2025-04-18T13:23:48.852489Z","shell.execute_reply":"2025-04-18T14:30:32.069465Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ptr2tahu\nSweep URL: https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: myykm01c with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_132356-myykm01c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/myykm01c' target=\"_blank\">silvery-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/myykm01c' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/myykm01c</a>"},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n100%|██████████| 330M/330M [00:01<00:00, 234MB/s] \n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 42.28%, Val Acc: 75.15%\nEpoch 2: Train Acc: 71.26%, Val Acc: 81.55%\nEpoch 3: Train Acc: 75.53%, Val Acc: 82.80%\nEpoch 4: Train Acc: 76.85%, Val Acc: 83.35%\nEpoch 5: Train Acc: 77.63%, Val Acc: 84.20%\nEpoch 6: Train Acc: 77.57%, Val Acc: 84.25%\nEpoch 7: Train Acc: 78.61%, Val Acc: 84.45%\nEpoch 8: Train Acc: 79.55%, Val Acc: 84.60%\nEpoch 9: Train Acc: 79.43%, Val Acc: 85.10%\nEpoch 10: Train Acc: 79.41%, Val Acc: 85.30%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>85.3</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>train_accuracy</td><td>79.40993</td></tr><tr><td>train_loss</td><td>0.6993</td></tr><tr><td>val_accuracy</td><td>85.3</td></tr><tr><td>val_loss</td><td>0.54427</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">silvery-sweep-1</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/myykm01c' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/myykm01c</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_132356-myykm01c/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 219evrtp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_134538-219evrtp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/219evrtp' target=\"_blank\">solar-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/219evrtp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/219evrtp</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 69.58%, Val Acc: 83.95%\nEpoch 2: Train Acc: 80.20%, Val Acc: 86.00%\nEpoch 3: Train Acc: 81.52%, Val Acc: 86.60%\nEpoch 4: Train Acc: 82.50%, Val Acc: 86.75%\nEpoch 5: Train Acc: 83.26%, Val Acc: 86.90%\nEpoch 6: Train Acc: 84.32%, Val Acc: 87.25%\nEpoch 7: Train Acc: 84.67%, Val Acc: 87.20%\nEpoch 8: Train Acc: 84.84%, Val Acc: 87.15%\nEpoch 9: Train Acc: 85.36%, Val Acc: 87.40%\nEpoch 10: Train Acc: 86.07%, Val Acc: 87.75%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▆▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>87.75</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>86.07326</td></tr><tr><td>train_loss</td><td>0.43099</td></tr><tr><td>val_accuracy</td><td>87.75</td></tr><tr><td>val_loss</td><td>0.39</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">solar-sweep-2</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/219evrtp' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/219evrtp</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_134538-219evrtp/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: be2ih0nn with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \taugment: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'DL_A2' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_140723-be2ih0nn</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/be2ih0nn' target=\"_blank\">warm-sweep-3</a></strong> to <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/sweeps/ptr2tahu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/be2ih0nn' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/be2ih0nn</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Acc: 48.14%, Val Acc: 80.85%\nEpoch 2: Train Acc: 76.13%, Val Acc: 83.20%\nEpoch 3: Train Acc: 78.01%, Val Acc: 84.15%\nEpoch 4: Train Acc: 79.82%, Val Acc: 84.55%\nEpoch 5: Train Acc: 80.02%, Val Acc: 85.30%\nEpoch 6: Train Acc: 80.95%, Val Acc: 85.30%\nEpoch 7: Train Acc: 81.42%, Val Acc: 85.95%\nEpoch 8: Train Acc: 81.90%, Val Acc: 86.25%\nEpoch 9: Train Acc: 82.04%, Val Acc: 85.75%\nEpoch 10: Train Acc: 82.37%, Val Acc: 85.95%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇██▇█</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_acc</td><td>86.25</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>lr</td><td>0.01</td></tr><tr><td>train_accuracy</td><td>82.3728</td></tr><tr><td>train_loss</td><td>0.5759</td></tr><tr><td>val_accuracy</td><td>85.95</td></tr><tr><td>val_loss</td><td>0.45992</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">warm-sweep-3</strong> at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/be2ih0nn' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2/runs/be2ih0nn</a><br> View project at: <a href='https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2' target=\"_blank\">https://wandb.ai/cs24m016-indian-institute-of-technology-madras/DL_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_140723-be2ih0nn/logs</code>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wandb\nfrom sklearn.metrics import confusion_matrix\nimport random\n\n\ndef evaluate_vit_test(model_path, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Transforms\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ])\n\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n    class_names = test_dataset.classes\n\n    # Load pre-trained ViT\n    model = models.vit_b_16(pretrained=False)\n\n    # Rebuild classifier head to match training setup\n    in_features = model.heads[0].in_features\n    model.heads = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(512, len(class_names))\n    )\n\n    # Load trained weights\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    all_preds, all_labels = [], []\n    correct = 0\n    sample_imgs = []\n\n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            sample_imgs.extend(imgs.cpu())\n\n    accuracy = 100 * correct / len(test_dataset)\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    wandb.init(project=\"DL_A2\", name=\"ViT Test Evaluation\")\n    wandb.log({\"vit_test_accuracy\": accuracy})\n\n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n    plt.title(\"Confusion Matrix - ViT\")\n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.xticks(rotation=45)\n    wandb.log({\"confusion_matrix_vit\": wandb.Image(plt)})\n    plt.close()\n\n    # Sample prediction grid\n    def show_predictions(images, labels, preds):\n        fig, axes = plt.subplots(5, 6, figsize=(15, 10))\n        for idx, ax in enumerate(axes.flat):\n            if idx >= len(images): break\n            img = images[idx].permute(1, 2, 0).numpy()\n            img = 0.5 * img + 0.5  # unnormalize\n            ax.imshow(np.clip(img, 0, 1))\n            color = 'green' if labels[idx] == preds[idx] else 'red'\n            ax.set_title(f\"True: {class_names[labels[idx]]}\\nPred: {class_names[preds[idx]]}\", color=color, fontsize=8)\n            ax.axis('off')\n        plt.tight_layout()\n        return fig\n\n    indices = random.sample(range(len(sample_imgs)), min(30, len(sample_imgs)))\n    sample_imgs_subset = [sample_imgs[i] for i in indices]\n    sample_labels_subset = [all_labels[i] for i in indices]\n    sample_preds_subset = [all_preds[i] for i in indices]\n\n    fig = show_predictions(sample_imgs_subset, sample_labels_subset, sample_preds_subset)\n    wandb.log({\"vit_test_predictions\": wandb.Image(fig)})\n    plt.close(fig)\n\n    wandb.finish()\n    return accuracy\n\n\n# Example usage\nif __name__ == \"__main__\":\n    evaluate_vit_test(\n        model_path=\"/kaggle/input/vit/pytorch/default/1/vit_best_model.pth\",\n        test_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val\"\n    )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}