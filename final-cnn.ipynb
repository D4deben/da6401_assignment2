{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n## Installing WandB\n!pip install wandb -qqq\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Device: \", device)\n\nfrom tqdm import tqdm\nimport wandb, os\nos.environ['WANDB_API_KEY'] = \"5203e53880ceb7b6d2c0a93809e14ae43261f2ed\" #your key here\nwandb.login()\n\n!pip install lightning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part A","metadata":{}},{"cell_type":"markdown","source":"## Question 1","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass ConvNet(nn.Module):\n    def __init__(\n        self,\n        input_shape=(3, 224, 224),\n        conv_filters=[32, 64, 128, 256, 512],\n        filter_sizes=[3, 3, 3, 3, 3],\n        activation_fn=nn.ReLU,\n        dense_units=256,\n        dense_activation_fn=nn.ReLU,\n        dropout_rate=0.3,\n        batch_norm=True,\n        num_classes=10\n    ):\n        super(ConvNet, self).__init__()\n\n        self.conv_blocks = nn.Sequential()\n        in_channels = input_shape[0]\n        h, w = input_shape[1], input_shape[2]\n\n        # Add 5 Conv-BN-Activation-Pool blocks\n        for i in range(5):\n            out_channels = conv_filters[i]\n            kernel_size = filter_sizes[i]\n            padding = kernel_size // 2  # keep same spatial size before pooling\n\n            self.conv_blocks.add_module(f\"conv{i+1}\", nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding))\n            if batch_norm:\n                self.conv_blocks.add_module(f\"bn{i+1}\", nn.BatchNorm2d(out_channels))\n            self.conv_blocks.add_module(f\"act{i+1}\", activation_fn())\n            self.conv_blocks.add_module(f\"pool{i+1}\", nn.MaxPool2d(2))\n            if dropout_rate > 0:\n                self.conv_blocks.add_module(f\"dropout{i+1}\", nn.Dropout2d(dropout_rate))\n\n            in_channels = out_channels\n            h, w = h // 2, w // 2  # due to MaxPool2d(2)\n\n        # Compute the flattened size after conv blocks\n        self.flattened_size = in_channels * h * w\n\n        self.fc1 = nn.Linear(self.flattened_size, dense_units)\n        self.fc1_act = dense_activation_fn()\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.output_layer = nn.Linear(dense_units, num_classes)\n\n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = x.view(x.size(0), -1)\n        x = self.dropout(self.fc1_act(self.fc1(x)))\n        return self.output_layer(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Question 2","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, random_split, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\n\ndef get_dataloaders(data_dir, batch_size=64, val_split=0.2, augment=True):\n    # Transforms\n    train_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor()\n    ]) if augment else transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    test_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor()\n    ])\n\n    full_dataset = ImageFolder(root=data_dir, transform=train_transforms)\n\n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(ImageFolder(root=data_dir, transform=test_transforms), val_idx)\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    return train_loader, val_loader, len(full_dataset.classes)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn.functional as F\nimport wandb\n\ndef train(model, train_loader, val_loader, optimizer, criterion, device, epochs=10):\n    model.to(device)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss, correct = 0, 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            correct += (outputs.argmax(dim=1) == labels).sum().item()\n\n        train_accuracy = correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_correct, val_loss = 0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n\n        val_accuracy = val_correct / len(val_loader.dataset)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": total_loss / len(train_loader),\n            \"train_accuracy\": train_accuracy,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_accuracy\n        })\n\n        print(f\"Epoch {epoch+1} - Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision import models\nfrom torch import optim\nimport torch.nn as nn\nimport wandb\n\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n\n    config = wandb.config\n\n    activation_map = {\n        \"ReLU\": nn.ReLU,\n        \"GELU\": nn.GELU,\n        \"SiLU\": nn.SiLU,\n        \"Mish\": nn.Mish\n    }\n\n    model = ConvNet(\n        input_shape=(3, 224, 224),\n        conv_filters=config.conv_filters,\n        filter_sizes=config.filter_sizes,\n        activation_fn=activation_map[config.activation_fn],\n        dense_units=config.dense_units,\n        dense_activation_fn=activation_map[config.activation_fn],\n        dropout_rate=config.dropout,\n        batch_norm=config.batch_norm,\n        num_classes=10\n    )\n\n    train_loader, val_loader, _ = get_dataloaders(\n        data_dir=\"/kaggle/input/nature-12k/inaturalist_12K/train\",\n        batch_size=config.batch_size,\n        augment=config.augment\n    )\n\n    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n\n    train(model, train_loader, val_loader, optimizer, criterion, device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), epochs=config.epochs)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[32, 32, 64, 64, 128], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3]]\n        },\n        \"activation_fn\": {\n            \"values\": [\"ReLU\", \"GELU\", \"SiLU\", \"Mish\"]\n        },\n        \"dropout\": {\n            \"values\": [0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128, 256]\n        },\n        \"batch_norm\": {\n            \"values\": [True, False]\n        },\n        \"augment\": {\n            \"values\": [True, False]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 10\n        }\n    }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=50)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Question 3","metadata":{}},{"cell_type":"code","source":"\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[32, 32, 64, 64, 128],[512,256,128,64,32],[256,128,64,64,32], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3],[5,5,5,5,5],[7,7,7,7,7],[7,7,5,5,3],[7,5,3,3,3]]\n        },\n        \"activation_fn\": {\n            \"values\": [\"ReLU\", \"GELU\", \"SiLU\", \"Mish\"]\n        },\n        \"dropout\": {\n            \"values\": [0.0,0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128, 256]\n        },\n        \"batch_norm\": {\n            \"values\": [True]\n        },\n        \"augment\": {\n            \"values\": [True, False]\n        },\n        \"batch_size\": {\n            \"values\": [64, 128,256]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 10\n        }\n    }\n}\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    # Enhanced data augmentation\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    \n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n    \n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n    \n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n                             num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, \n                           num_workers=4, pin_memory=True)\n    \n    return train_loader, val_loader, full_dataset.classes\n\nclass OptimizedCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n        \n        # Larger filters in early layers, smaller in later layers\n        self.conv_blocks = nn.Sequential(\n            # Block 1: 64 filters, 7x7 kernel\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 2: 128 filters, 5x5 kernel\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 3: 256 filters, 3x3 kernel\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 4: 512 filters, 3x3 kernel\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 5: 512 filters, 3x3 kernel\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, num_classes))\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, 0, 0.01)\n                init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=20):\n    model.to(device)\n    best_val_acc = 0.0\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_correct += predicted.eq(labels).sum().item()\n        \n        train_acc = 100 * train_correct / len(train_loader.dataset)\n        \n        # Validation\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                val_correct += outputs.argmax(1).eq(labels).sum().item()\n        \n        val_acc = 100 * val_correct / len(val_loader.dataset)\n        \n        # Step the scheduler\n        scheduler.step(val_loss)\n        \n        # Log metrics\n        wandb.log({            \n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n        \n        print(f\"Epoch {epoch+1}/{epochs} - \"\n              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n              f\"Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n    \n    return best_val_acc\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n    \n    # Device configuration\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Get data loaders\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/nature-12k/inaturalist_12K/train\",\n        batch_size=256,\n        augment=True\n    )\n    \n    # Initialize model\n    model = OptimizedCNN(num_classes=len(classes))\n    \n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n    \n    # Optimizer with momentum and weight decay\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    \n    # Train the model\n    best_val_acc = train(\n        model, train_loader, val_loader, \n        optimizer, criterion, scheduler,\n        device=device, epochs=20\n    )\n    \n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Question 4","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\n\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\n        \"name\": \"val_accuracy\",\n        \"goal\": \"maximize\"\n    },\n    \"parameters\": {\n        \"conv_filters\": {\n            \"values\": [[256,128,64,64,32], [32, 64, 128, 256, 512]]\n        },\n        \"filter_sizes\": {\n            \"values\": [[3, 3, 3, 3, 3],[7,7,7,7,7]]\n        },\n        \"activation_fn\": {\n            \"values\": [ \"GELU\"]\n        },\n        \"dropout\": {\n            \"values\": [0.2, 0.3]\n        },\n        \"dense_units\": {\n            \"values\": [128]\n        },\n        \"batch_norm\": {\n            \"values\": [True]\n        },\n        \"augment\": {\n            \"values\": [False]\n        },\n        \"batch_size\": {\n            \"values\": [64,256]\n        },\n        \"lr\": {\n            \"values\": [0.01, 0.001]\n        },\n        \"epochs\": {\n            \"value\": 30\n        }\n    }\n}\n\n\n\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    # Enhanced data augmentation\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    \n    # Stratified split\n    targets = np.array(full_dataset.targets)\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n    \n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n    \n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n                             num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, \n                           num_workers=4, pin_memory=True)\n    \n    return train_loader, val_loader, full_dataset.classes\n\nclass OptimizedCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super(OptimizedCNN, self).__init__()\n        \n        # Larger filters in early layers, smaller in later layers\n        self.conv_blocks = nn.Sequential(\n            # Block 1: 64 filters, 7x7 kernel\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 2: 128 filters, 5x5 kernel\n            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 3: 256 filters, 3x3 kernel\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 4: 512 filters, 3x3 kernel\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n            \n            # Block 5: 512 filters, 3x3 kernel\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Sequential(\n            nn.Linear(512, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, num_classes))\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    init.constant_(m.bias, 0)\n            elif isinstance(m, nn.BatchNorm2d):\n                init.constant_(m.weight, 1)\n                init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                init.normal_(m.weight, 0, 0.01)\n                init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        x = self.conv_blocks(x)\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=20):\n    model.to(device)\n    best_val_acc = 0.0\n    \n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_correct += predicted.eq(labels).sum().item()\n        \n        train_acc = 100 * train_correct / len(train_loader.dataset)\n        \n        # Validation\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                val_correct += outputs.argmax(1).eq(labels).sum().item()\n        \n        val_acc = 100 * val_correct / len(val_loader.dataset)\n        \n        # Step the scheduler\n        scheduler.step(val_loss)\n        \n        # Log metrics\n        wandb.log({            \n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n        \n        print(f\"Epoch {epoch+1}/{epochs} - \"\n              f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n              f\"Train Acc: {train_acc:.2f}%, \"\n              f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n              f\"Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n    \n    return best_val_acc\n\ndef main():\n    wandb.init(project=\"DL_A2\")\n    \n    # Device configuration\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Get data loaders\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=256,\n        augment=True\n    )\n    \n    # Initialize model\n    model = OptimizedCNN(num_classes=len(classes))\n    \n    # Loss function\n    criterion = nn.CrossEntropyLoss()\n    \n    # Optimizer with momentum and weight decay\n    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)\n    \n    # Learning rate scheduler\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    \n    # Train the model\n    best_val_acc = train(\n        model, train_loader, val_loader, \n        optimizer, criterion, scheduler,\n        device=device, epochs=30\n    )\n    \n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep=sweep_config, project='DL_A2')\nwandb.agent(sweep_id, function=main, count=20)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Visualization on Test dataset.","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom collections import defaultdict\nimport wandb\nimport random\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ndef create_prediction_grid(images, labels, preds, class_names, n_rows=10, n_cols=3, title=\"Predictions\"):\n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows*2))\n    fig.suptitle(title, fontsize=16, y=1.02)\n    \n    for i in range(n_rows):\n        for j in range(n_cols):\n            idx = i * n_cols + j\n            if idx >= len(images):\n                break\n                \n            ax = axes[i,j]\n            img = images[idx].numpy().transpose((1, 2, 0))\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img = np.clip((img * std + mean), 0, 1)\n            \n            ax.imshow(img)\n            ax.axis('off')\n            \n            true_label = class_names[labels[idx]]\n            pred_label = class_names[preds[idx]]\n            is_correct = preds[idx] == labels[idx]\n            \n            title_color = 'green' if is_correct else 'red'\n            title_text = f\"True: {true_label}\\nPred: {pred_label}\"\n            ax.set_title(title_text, fontsize=9, color=title_color, pad=2)\n    \n    plt.tight_layout()\n    return fig\n\ndef evaluate_testset(model_path, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Same transforms as validation\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Load test dataset\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=4)\n    class_names = test_dataset.classes\n\n    # Load model\n    model = OptimizedCNN(num_classes=len(class_names))\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    # Collect predictions and ground truth\n    all_images = []\n    all_labels = []\n    all_preds = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_images.extend(images.cpu())\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(preds.cpu().numpy())\n\n    # Calculate overall accuracy\n    accuracy = 100 * np.sum(np.array(all_labels) == np.array(all_preds)) / len(all_labels)\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    # Initialize wandb\n    wandb.init(project=\"DL_A2\", name=\"test_evaluation\", job_type=\"eval\")\n    wandb.log({\"test_accuracy\": accuracy})\n\n    # Calculate class-wise accuracy\n    class_correct = defaultdict(int)\n    class_total = defaultdict(int)\n    \n    for label, pred in zip(all_labels, all_preds):\n        class_total[label] += 1\n        if label == pred:\n            class_correct[label] += 1\n    \n    # Create accuracy table\n    accuracy_table = wandb.Table(columns=[\"Class\", \"Accuracy\", \"Samples\"])\n    for class_idx in range(len(class_names)):\n        if class_total[class_idx] > 0:\n            acc = 100 * class_correct[class_idx] / class_total[class_idx]\n        else:\n            acc = float('nan')\n        accuracy_table.add_data(class_names[class_idx], acc, class_total[class_idx])\n    \n    wandb.log({\"class_accuracy\": accuracy_table})\n\n    # Create confusion matrix (only for classes with samples)\n    present_classes = [c for c in range(len(class_names)) if class_total[c] > 0]\n    if present_classes:\n        cm = confusion_matrix(all_labels, all_preds, labels=present_classes)\n        plt.figure(figsize=(12, 10))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                   xticklabels=[class_names[c] for c in present_classes],\n                   yticklabels=[class_names[c] for c in present_classes])\n        plt.title('Confusion Matrix')\n        plt.ylabel('True Label')\n        plt.xlabel('Predicted Label')\n        plt.xticks(rotation=45, ha='right')\n        plt.yticks(rotation=0)\n        wandb.log({\"confusion_matrix\": wandb.Image(plt)})\n        plt.close()\n\n    # Create 10x3 prediction grid\n    num_samples = 30  # 10 rows x 3 columns\n    if len(all_images) >= num_samples:\n        indices = random.sample(range(len(all_images)), num_samples)\n        sample_images = [all_images[i] for i in indices]\n        sample_labels = [all_labels[i] for i in indices]\n        sample_preds = [all_preds[i] for i in indices]\n        \n        grid_fig = create_prediction_grid(\n            sample_images, sample_labels, sample_preds, \n            class_names, title=\"Test Set Predictions (Random Sample)\"\n        )\n        wandb.log({\"prediction_grid\": wandb.Image(grid_fig)})\n        plt.close(grid_fig)\n    else:\n        print(f\"Not enough samples ({len(all_images)}) to create full 10x3 grid\")\n\n    wandb.finish()\n\nif __name__ == \"__main__\":\n    evaluate_testset(\n        model_path='/kaggle/input/cnn/pytorch/default/1/best_model.pth',\n        test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val'\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feature map and Filter Analysis","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport wandb\n\ndef visualize_first_layer(model, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Load transformation\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load test dataset and get random image\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    random_idx = np.random.randint(0, len(test_dataset))\n    img, label = test_dataset[random_idx]\n    img = img.unsqueeze(0).to(device)  # Add batch dimension\n    \n    # Get the first convolutional layer\n    first_conv = model.conv_blocks[0]\n    num_filters = first_conv.out_channels  # Dynamically get number of filters\n    \n    # Visualize filters\n    filters = first_conv.weight.data.cpu().numpy()\n    \n    # Normalize filters to 0-1 for visualization\n    f_min, f_max = filters.min(), filters.max()\n    filters = (filters - f_min) / (f_max - f_min)\n    \n    # Calculate grid size (square as possible)\n    grid_size = int(np.ceil(np.sqrt(num_filters)))\n    \n    # Plot filters\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        # Show first channel only (assuming RGB input)\n        plt.imshow(filters[i, 0], cmap='gray')\n        plt.axis('off')\n    plt.suptitle(f'First Layer Filters ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    filters_fig = plt.gcf()\n    \n    # Get feature maps\n    model.eval()\n    with torch.no_grad():\n        feature_maps = first_conv(img)\n    \n    # Normalize feature maps\n    fmaps = feature_maps.squeeze(0).cpu().numpy()\n    fmap_min, fmap_max = fmaps.min(), fmaps.max()\n    fmaps = (fmaps - fmap_min) / (fmap_max - fmap_min)\n    \n    # Plot feature maps\n    plt.figure(figsize=(12, 12))\n    for i in range(num_filters):\n        plt.subplot(grid_size, grid_size, i+1)\n        plt.imshow(fmaps[i], cmap='viridis')\n        plt.axis('off')\n    plt.suptitle(f'Feature Maps ({num_filters} total)', fontsize=16)\n    plt.tight_layout()\n    fmap_fig = plt.gcf()\n    \n    # Show original image (denormalized)\n    img_denorm = img.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n    img_denorm = img_denorm * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n    img_denorm = np.clip(img_denorm, 0, 1)\n    \n    plt.figure(figsize=(8, 8))\n    plt.imshow(img_denorm)\n    plt.title(f'Original Test Image\\nClass: {test_dataset.classes[label]}')\n    plt.axis('off')\n    orig_fig = plt.gcf()\n    \n    # Additional analysis\n    # 1. Filter magnitude distribution (fixed calculation)\n    filter_magnitudes = torch.norm(first_conv.weight.data.view(num_filters, -1), p=2, dim=1).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.hist(filter_magnitudes, bins=20)\n    plt.title('Filter Magnitude Distribution')\n    plt.xlabel('Magnitude (L2 norm)')\n    plt.ylabel('Count')\n    magnitude_fig = plt.gcf()\n    \n    # 2. Activation statistics\n    activation_means = feature_maps.mean(dim=(0, 2, 3)).cpu().numpy()\n    activation_max = feature_maps.amax(dim=(0, 2, 3)).cpu().numpy()\n    \n    plt.figure(figsize=(10, 5))\n    plt.bar(range(num_filters), activation_means, alpha=0.5, label='Mean')\n    plt.bar(range(num_filters), activation_max, alpha=0.5, label='Max')\n    plt.title('Feature Map Activation Statistics')\n    plt.xlabel('Filter Index')\n    plt.ylabel('Activation Value')\n    plt.legend()\n    activation_fig = plt.gcf()\n    \n    # Log to wandb\n    wandb.init(project=\"DL_A2\", name=\"filter_visualization\")\n    wandb.log({\n        \"original_image\": wandb.Image(orig_fig),\n        \"first_layer_filters\": wandb.Image(filters_fig),\n        \"feature_maps\": wandb.Image(fmap_fig),\n        \"filter_magnitudes\": wandb.Image(magnitude_fig),\n        \"activation_stats\": wandb.Image(activation_fig),\n        \"selected_class\": test_dataset.classes[label]\n    })\n    \n    plt.close('all')\n    return {\n        \"num_filters\": num_filters,\n        \"filter_magnitudes\": filter_magnitudes,\n        \"activation_means\": activation_means,\n        \"activation_max\": activation_max\n    }\n\n# Load your model\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntest_dataset = datasets.ImageFolder(root='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val', transform=transforms.ToTensor())\nmodel = OptimizedCNN(num_classes=len(test_dataset.classes))\nmodel.load_state_dict(torch.load('/kaggle/input/cnn/pytorch/default/1/best_model.pth', map_location=device))\nmodel = model.to(device)\n\n# Run visualization\nresults = visualize_first_layer(\n    model, \n    test_dir='/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val'\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Part B","metadata":{}},{"cell_type":"markdown","source":"## Question 7","metadata":{}},{"cell_type":"markdown","source":"### training The model","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets, models\nfrom torch.utils.data import DataLoader, Subset\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport numpy as np\nimport wandb\n\n\n# ------------------------ Sweep Config ------------------------ #\nsweep_config = {\n    \"method\": \"random\",\n    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"augment\": {\"values\": [True, False]},\n        \"batch_size\": {\"values\": [64, 256]},\n        \"lr\": {\"values\": [0.01, 0.001]},\n        \"epochs\": {\"value\": 10}\n    }\n}\n\n\n# ------------------------ Data Loader ------------------------ #\ndef get_dataloaders(data_dir, batch_size=256, val_split=0.2, augment=True):\n    train_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(15),\n        transforms.ColorJitter(0.2, 0.2, 0.2),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]) if augment else transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    val_transforms = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ])\n\n    full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)\n    targets = np.array(full_dataset.targets)\n\n    splitter = StratifiedShuffleSplit(n_splits=1, test_size=val_split, random_state=42)\n    train_idx, val_idx = next(splitter.split(np.zeros(len(targets)), targets))\n\n    train_set = Subset(full_dataset, train_idx)\n    val_set = Subset(datasets.ImageFolder(root=data_dir, transform=val_transforms), val_idx)\n\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n    return train_loader, val_loader, full_dataset.classes\n\n\n# ------------------------ Training Function ------------------------ #\ndef train(model, train_loader, val_loader, optimizer, criterion, scheduler, device, epochs=30):\n    model.to(device)\n    best_val_acc = 0\n\n    for epoch in range(epochs):\n        # Progressive Unfreezing\n        if epoch == 5:\n            for name, param in model.named_parameters():\n                if \"encoder.layer.10\" in name or \"encoder.layer.11\" in name:\n                    param.requires_grad = True\n\n        model.train()\n        train_loss, correct = 0, 0\n        for x, y in train_loader:\n            x, y = x.to(device), y.to(device)\n            optimizer.zero_grad()\n            out = model(x)\n            loss = criterion(out, y)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            correct += (out.argmax(1) == y).sum().item()\n        train_acc = 100. * correct / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_loss, val_correct = 0, 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x, y = x.to(device), y.to(device)\n                out = model(x)\n                loss = criterion(out, y)\n                val_loss += loss.item()\n                val_correct += (out.argmax(1) == y).sum().item()\n        val_acc = 100. * val_correct / len(val_loader.dataset)\n        scheduler.step(val_loss)\n\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": train_loss / len(train_loader),\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss / len(val_loader),\n            \"val_accuracy\": val_acc,\n            \"lr\": optimizer.param_groups[0]['lr']\n        })\n\n        print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"best_model_vit.pth\")\n\n    return best_val_acc\n\n\n# ------------------------ Main Function ------------------------ #\ndef main():\n    wandb.init(project=\"DL_A2\")\n    config = wandb.config\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_loader, val_loader, classes = get_dataloaders(\n        data_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/train\",\n        batch_size=config.batch_size,\n        augment=config.augment\n    )\n\n    # Load pre-trained ViT\n    vit = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n\n    # Freeze all layers first\n    for param in vit.parameters():\n        param.requires_grad = False\n\n    # Replace classifier head\n    in_features = vit.heads[0].in_features\n    vit.heads = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.3),\n        nn.Linear(512, len(classes))\n    )\n\n    # Enable training on new head\n    for param in vit.heads.parameters():\n        param.requires_grad = True\n\n    optimizer = optim.SGD(vit.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-5)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n    criterion = nn.CrossEntropyLoss()\n\n    best_val_acc = train(\n        model=vit,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        optimizer=optimizer,\n        criterion=criterion,\n        scheduler=scheduler,\n        device=device,\n        epochs=config.epochs\n    )\n\n    wandb.summary[\"best_val_acc\"] = best_val_acc\n    wandb.finish()\n\n\n# ------------------------ Start Sweep ------------------------ #\nsweep_id = wandb.sweep(sweep_config, project=\"DL_A2\")\nwandb.agent(sweep_id, function=main, count=20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Test the model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wandb\nfrom sklearn.metrics import confusion_matrix\nimport random\n\n\ndef evaluate_vit_test(model_path, test_dir):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Transforms\n    transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5]*3, [0.5]*3)\n    ])\n\n    test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n    class_names = test_dataset.classes\n\n    # Load pre-trained ViT\n    model = models.vit_b_16(pretrained=False)\n\n    # Rebuild classifier head to match training setup\n    in_features = model.heads[0].in_features\n    model.heads = nn.Sequential(\n        nn.Linear(in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(512, len(class_names))\n    )\n\n    # Load trained weights\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n\n    all_preds, all_labels = [], []\n    correct = 0\n    sample_imgs = []\n\n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            sample_imgs.extend(imgs.cpu())\n\n    accuracy = 100 * correct / len(test_dataset)\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n\n    wandb.init(project=\"DL_A2\", name=\"ViT Test Evaluation\")\n    wandb.log({\"vit_test_accuracy\": accuracy})\n\n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n    plt.title(\"Confusion Matrix - ViT\")\n    plt.ylabel(\"True Label\")\n    plt.xlabel(\"Predicted Label\")\n    plt.xticks(rotation=45)\n    wandb.log({\"confusion_matrix_vit\": wandb.Image(plt)})\n    plt.close()\n\n    # Sample prediction grid\n    def show_predictions(images, labels, preds):\n        fig, axes = plt.subplots(5, 6, figsize=(15, 10))\n        for idx, ax in enumerate(axes.flat):\n            if idx >= len(images): break\n            img = images[idx].permute(1, 2, 0).numpy()\n            img = 0.5 * img + 0.5  # unnormalize\n            ax.imshow(np.clip(img, 0, 1))\n            color = 'green' if labels[idx] == preds[idx] else 'red'\n            ax.set_title(f\"True: {class_names[labels[idx]]}\\nPred: {class_names[preds[idx]]}\", color=color, fontsize=8)\n            ax.axis('off')\n        plt.tight_layout()\n        return fig\n\n    indices = random.sample(range(len(sample_imgs)), min(30, len(sample_imgs)))\n    sample_imgs_subset = [sample_imgs[i] for i in indices]\n    sample_labels_subset = [all_labels[i] for i in indices]\n    sample_preds_subset = [all_preds[i] for i in indices]\n\n    fig = show_predictions(sample_imgs_subset, sample_labels_subset, sample_preds_subset)\n    wandb.log({\"vit_test_predictions\": wandb.Image(fig)})\n    plt.close(fig)\n\n    wandb.finish()\n    return accuracy\n\n\n# Example usage\nif __name__ == \"__main__\":\n    evaluate_vit_test(\n        model_path=\"/kaggle/input/vit/pytorch/default/1/vit_best_model.pth\",\n        test_dir=\"/kaggle/input/d/d4debeniitm/nature-12k/inaturalist_12K/val\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}